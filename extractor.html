<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Form Suite â€” Extractor</title>
  <link rel="icon" href="favicon.ico" type="image/gif" sizes="32x32">
  <link rel="shortcut icon" href="favicon.ico" type="image/gif">
  <meta name="viewport" content="width=device-width,initial-scale=1" />

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
  <link rel="stylesheet" href="style.css">

  <!-- Persistence layer (provides window.formSuitePersist) -->
  <script src="persistence.js"></script>
  <!-- flatpickr JS (date inputs) -->
  <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>
  <!-- JSZip for JS-based SDT scanning (parity with Tag Matcher) -->
  <script src="https://cdn.jsdelivr.net/npm/jszip@3.10.1/dist/jszip.min.js"></script>
  <!-- for the autocompletion of the adress-->
  <script src="address-autocomplete.js"></script>
</head>
<body>
  <header>
    <div class="row">
      <span class="brand logo-md">
        <img src="logo.gif" alt="Form Suite logo" class="logo" />
        <strong>Form Suite</strong>
      </span>
      <span class="muted">Â·</span><a href="index.html">Form</a>
      <span class="muted">Â·</span><a href="builder.html" id="openBuilder">Form Builder</a>
      <span class="muted">Â·</span><a href="matcher.html">Tag Matcher</a>
      <span class="muted">Â·</span><a href="rules.html">Rules</a>
      <span class="muted">Â·</span><span class="muted">Extractor</span>
    </div>
  </header>

  <main>
    <section class="panel">
      <h2 style="margin:0 0 10px">Inspect SDTs & store manual form payload in the DOCX</h2>
      <div class="row" style="gap:8px;flex-wrap:wrap">
        <button id="btnOpen">Open DOCXâ€¦</button>
        <button id="btnSave" disabled>Save (payload only)</button>
        <button id="btnExport" disabled>Export (payload + replace tags)</button>
        <span class="muted" id="status" style="margin-left:auto">Idle</span>
      </div>

      <!-- Restored banner -->
      <div id="permNote" class="note warn" style="display:none;margin-top:10px">
        This DOCX was opened via picker but I donâ€™t have write permission to the original file.
        Clicking <em>Save</em> will download a copy instead of writing back.
        <button id="btnRegrant" class="ghost" style="margin-left:8px">Grant write access</button>
      </div>
    </section>

    <div class="grid-3">
      <section class="panel">
        <details>
          <summary><strong>Found SDTs</strong></summary>
          <div style="overflow:auto;">
            <table id="sdt-table">
              <thead>
                <tr>
                  <th>#</th>
                  <th>Part</th>
                  <th>w:tag</th>
                  <th>w:alias</th>
                  <th>Text</th>
                </tr>
              </thead>
              <tbody id="sdt-tbody"></tbody>
            </table>
          </div>
        </details>
      </section>

      <section class="panel">
        <details>
          <summary><strong>CRONOS_PAYLOAD Preview</strong></summary>
          <textarea id="payloadPreview" spellcheck="false" style="min-height:420px"></textarea>
          <div class="row" style="margin-top:6px; gap:8px;">
            <button id="btnSaveFromPreview" class="secondary" disabled>Save</button>
            <span class="muted" id="previewStatus"></span>
          </div>
        </details>
      </section>

      <section class="panel">
        <details>
          <summary><strong>Headers/Subheaders</strong></summary>
          <div id="headersTree" class="tree" style="max-height:420px;overflow:auto;padding:6px 4px;"></div>
        </details>
      </section>

      <section class="panel">
        <details>
          <summary><strong>Live Form (from payload schema)</strong></summary>
          <div id="formMount"></div>
        </details>
      </section>
    </div>
  </main>

  <script>
    // =========================
    // ðŸ”Ž DEBUG / TRACE PRIMITIVES
    // =========================
      const DEBUG = { on: true, seq: 0 };
      const _t = () => new Date().toISOString().slice(11, 23);
      const tag = (name) => `%c[Extractor ${_t()} #${++DEBUG.seq}] ${name}`;
      const tagStyle = 'color:#6b7280;font-weight:600';

      function TRACE(name, details) {
        const label = `${name} :: ${_t()} :: #${DEBUG.seq+1}`;
        let ended = false;
        try {
          console.groupCollapsed(tag(name), tagStyle, details ?? '');
        } catch {}
        try {
          console.time(label);
        } catch {}
        return {
          step: (msg, data) => console.log(tag(`  â†³ ${msg}`), tagStyle, data ?? ''),
          warn: (msg, data) => console.warn(tag(`  âš  ${msg}`), tagStyle, data ?? ''),
          error: (msg, err) => console.error(tag(`  âœ– ${msg}`), tagStyle, err),
          end: (extra) => {
            if (ended) return;
            ended = true;
            if (extra) console.log(tag('done'), tagStyle, extra);
            try { console.timeEnd(label); } catch {}
            try { console.groupEnd(); } catch {}
          }
        };
      }

    window.addEventListener('error', (e) => {
      console.error(tag('window.error'), tagStyle, { message: e.message, filename: e.filename, lineno: e.lineno, colno: e.colno, error: e.error });
    });
    window.addEventListener('unhandledrejection', (e) => {
      console.error(tag('window.unhandledrejection'), tagStyle, e.reason);
    });

    // =========================
    // ðŸ§­ PAYLOAD CHANGE FORENSICS (WHY DID IT WRITE?)
    // =========================
    function __safeLen(x){ return Array.isArray(x) ? x.length : (x && typeof x==='object' ? Object.keys(x).length : 0); }
    function __deepEqual(a,b){ try { return JSON.stringify(a) === JSON.stringify(b); } catch { return false; } }
    function __diffObj(a, b, path = '') {
      const diffs = [];
      const isObj = v => v && typeof v === 'object' && !Array.isArray(v);
      const keys = new Set([...Object.keys(a||{}), ...Object.keys(b||{})]);
      for (const k of keys) {
        const pa = path ? `${path}.${k}` : k;
        const va = a?.[k], vb = b?.[k];
        if (isObj(va) && isObj(vb)) { diffs.push(...__diffObj(va, vb, pa)); continue; }
        if (Array.isArray(va) && Array.isArray(vb)) {
          if (!__deepEqual(va, vb)) diffs.push({ path: pa, type:'array', from: va, to: vb });
          continue;
        }
        if (JSON.stringify(va) !== JSON.stringify(vb)) diffs.push({ path: pa, type:'value', from: va, to: vb });
      }
      return diffs;
    }
    async function __snapshotCanonicalFromState(docId){
      const st = docId ? (await window.formSuitePersist.loadState(docId) || {}) : {};
      const p = st?.payload?.CRONOS_PAYLOAD || st?.CRONOS_PAYLOAD || st?.cronos_payload || {};
      return {
        ws: {
          rules: Array.isArray(st.rules) ? st.rules : [],
          fieldRules: Array.isArray(st.fieldRules) ? st.fieldRules : [],
          rulesVersion: st.rulesVersion,
          schema: st.schema,
          values: st.values,
          tagMap: st.tagMap,
        },
        payload: p
      };
    }
    async function debugLogExtractor(where, reasonFlags, beforeCanon, afterCanon){
      const label = `[Extractor:payload][${where}]`;
      try {
        console.groupCollapsed(label);
        console.log('docId:', gDocId, 'file:', `${gFileName || ''}.${gFileExt || ''}`);
        console.log('reasonFlags:', reasonFlags);
        const pre = beforeCanon || await __snapshotCanonicalFromState(gDocId);
        console.log('BEFORE (workspace.rules, workspace.fieldRules):',
          __safeLen(pre.ws.rules), __safeLen(pre.ws.fieldRules));
        console.log('BEFORE (payload.rules, payload.fieldRules):',
          __safeLen(pre.payload.rules), __safeLen(pre.payload.fieldRules));
        console.log('BEFORE payload.updatedAt:', pre.payload?.updatedAt, 'rulesVersion:', pre.payload?.rulesVersion);
        if (afterCanon) {
          console.log('AFTER payload.rules:', __safeLen(afterCanon.rules), afterCanon.rules);
          console.log('AFTER payload.fieldRules:', __safeLen(afterCanon.fieldRules), afterCanon.fieldRules);
          console.log('AFTER payload.updatedAt:', afterCanon.updatedAt, 'rulesVersion:', afterCanon.rulesVersion);
          const diffs = __diffObj(pre.payload || {}, afterCanon || {});
          if (diffs.length) console.warn('DIFF (payload changes):', diffs);
          else console.log('DIFF: none (payload unchanged)');
        }
      } catch (e) { console.error(label + ' failed', e); }
      finally { console.groupEnd(); }
    }

    // =========================
    // CONSTANTS & STATE
    // =========================
    const STORAGE_KEY  = 'FORM_SCHEMA_V1';
    const PAYLOAD_KEY  = 'CRONOS_PAYLOAD';
    const META_LS_KEY  = 'FS_CURRENT_DOC_META';       // legacy mirror
    const ACTIVE_LS_KEY= 'FS_ACTIVE_DOC_META';        // canonical
    const supportsFS   = 'showOpenFilePicker' in window && 'showSaveFilePicker' in window;

    let gArrayBuffer   = null;
    let gFileName      = null;  // name without .docx
    let gFileHandle    = null;  // FileSystemFileHandle
    let gSchema        = { title: 'Form', fields: [] };
    let gValues        = {};
    let gDocId         = null;
    let gDirty         = false;
    let gSDTs          = [];
    let gLastSchemaPushTs = 0;
    let gPreferDocOnNextLoad = false;   // prefer DOCX payload only right after doOpen()
    let gFileExt = 'docx'; // 'docx' | 'docm' | 'dotx' | 'dotm'
    let gHeadingBaseline = { flat: [], tree: [] };

    // NEW: hold structured address values while editing
    const __addressValues = Object.create(null);

    // UI refs
    const btnOpen   = document.getElementById('btnOpen');
    const btnSave   = document.getElementById('btnSave');
    const btnExport = document.getElementById('btnExport');
    const statusEl  = document.getElementById('status');
    const permNote  = document.getElementById('permNote');
    const payloadEl = document.getElementById('payloadPreview');
    const formMount = document.getElementById('formMount');
    const tableBody = document.getElementById('sdt-tbody');
    const btnRegrant= document.getElementById('btnRegrant');
    const btnSaveFromPreview = document.getElementById('btnSaveFromPreview');
    const previewStatus = document.getElementById('previewStatus');
    const headersTreeEl = document.getElementById('headersTree');

    function splitNameAndExt(fileName) {
      const m = String(fileName).match(/\.(docx|docm|dotx|dotm)$/i);
      return {
        base: String(fileName).replace(/\.(docx|docm|dotx|dotm)$/i, ''),
        ext:  (m ? m[1] : 'docx').toLowerCase()
      };
    }

    function wordMimeFor(ext) {
      switch ((ext || '').toLowerCase()) {
        case 'docm': return 'application/vnd.ms-word.document.macroEnabled.12';
        case 'dotx': return 'application/vnd.openxmlformats-officedocument.wordprocessingml.template';
        case 'dotm': return 'application/vnd.ms-word.template.macroEnabled.12';
        default:     return 'application/vnd.openxmlformats-officedocument.wordprocessingml.document';
      }
    }

    async function sha256Hex(bufOrU8) {
      const tr = TRACE('sha256Hex', { type: (bufOrU8?.constructor?.name), len: bufOrU8?.byteLength || bufOrU8?.length });
      try {
        const ab = (bufOrU8 instanceof ArrayBuffer) ? bufOrU8
                  : (bufOrU8?.buffer instanceof ArrayBuffer) ? bufOrU8.buffer
                  : new Uint8Array(bufOrU8 || []).buffer;
        const d = await crypto.subtle.digest('SHA-256', ab);
        const hex = [...new Uint8Array(d)].map(b => b.toString(16).padStart(2, '0')).join('');
        tr.end({ hex });
        return hex;
      } catch (e) { tr.error('sha failed', e); tr.end(); return '(hash-error)'; }
    }

    const setStatus = (m) => {
      const tr = TRACE('setStatus', { text: m });
      try { statusEl.textContent = m; } finally { tr.end(); }
    };

    // ===== Helpers to normalize/compact Pyodide byte outputs =====
    const toU8 = (x) => (x instanceof Uint8Array ? x : new Uint8Array(x));
    const compactU8 = (u8) => (u8.byteOffset === 0 && u8.byteLength === u8.buffer.byteLength) ? u8 : u8.slice();

    // =========================
    // PERSISTENCE SHIM (if missing)
    // =========================
    (function ensurePersist() {
      const tr = TRACE('ensurePersist');
      try {
        if (window.formSuitePersist) { tr.step('already present'); return; }
        tr.step('installing shim');
        let _meta = null;
        let _state = {};
        window.formSuitePersist = {
          getCurrentDocMeta() { tr.step('shim.getCurrentDocMeta', _meta); return _meta; },
          setCurrentDoc: async ({ bytes, handle, name }) => { tr.step('shim.setCurrentDoc', { bytes: !!bytes, name, handle: !!handle }); _meta = { docId: 'inline-' + Date.now(), name: name || 'document' }; return _meta; },
          setCurrentDocFromBytes: async (bytes, meta) => { tr.step('shim.setCurrentDocFromBytes', { bytes: !!bytes, meta }); _meta = { docId: 'inline-' + Date.now(), name: meta?.name || 'document' }; return _meta; },
          getCurrentDocBytes: async () => { tr.step('shim.getCurrentDocBytes -> null'); return null; },
          getBytes: async (_docId) => { tr.step('shim.getBytes -> null', _docId); return null; },
          getHandle: async (_docId) => { tr.step('shim.getHandle -> null', _docId); return null; },
          saveState: async (_docId, obj) => { tr.step('shim.saveState', { docId:_docId, keys:Object.keys(obj||{}) }); _state = { ..._state, ...(obj||{}) }; },
          loadState: async (_docId) => { tr.step('shim.loadState', { docId:_docId }); return _state; },
          putBytes: async (_docId, _bytes) => { tr.step('shim.putBytes', { docId:_docId, len: _bytes?.byteLength }); },
          ensurePermission: async (_h, _mode) => { tr.step('shim.ensurePermission', { mode:_mode }); return 'granted'; }
        };
      } finally {
        tr.end();
      }
    })();


    // =========================
    // CROSS-TAB + LOCALSTORAGE
    // =========================
    const bcLegacy = ('BroadcastChannel' in window) ? new BroadcastChannel('form-suite-doc') : null;
    const bcCanon  = ('BroadcastChannel' in window) ? new BroadcastChannel('fs-active-doc') : null;

    function persistActiveMeta(meta) {
      try { localStorage.setItem(ACTIVE_LS_KEY, JSON.stringify({ docId: meta?.docId, name: meta?.name })); } catch {}
      try { localStorage.setItem(META_LS_KEY,   JSON.stringify({ docId: meta?.docId, name: meta?.name })); } catch {}
      try { bcCanon?.postMessage({ type: 'active:set', docId: meta?.docId, name: meta?.name, ts: Date.now() }); } catch {}
      try { bcLegacy?.postMessage({ type: 'doc-switched', docId: meta?.docId, name: meta?.name, ts: Date.now() }); } catch {}
    }
    function readActiveMeta() {
      try {
        const v = localStorage.getItem(ACTIVE_LS_KEY) || localStorage.getItem(META_LS_KEY);
        return v ? JSON.parse(v) : null;
      } catch { return null; }
    }
    function announceDocSwitch() {
      persistActiveMeta({ docId: gDocId, name: gFileName });
    }
    function announceDocUpdate() {
      try { bcLegacy?.postMessage({ type: 'doc-updated', docId: gDocId, name: gFileName, ts: Date.now() }); } catch {}
      try { bcCanon?.postMessage({ type: 'active:updated', docId: gDocId, name: gFileName, ts: Date.now() }); } catch {}
    }
    function clearActiveMeta() {
      try { localStorage.removeItem(ACTIVE_LS_KEY); } catch {}
      try { localStorage.removeItem(META_LS_KEY); } catch {}
      try { bcCanon?.postMessage({ type: 'active:clear', ts: Date.now() }); } catch {}
      try { bcLegacy?.postMessage({ type: 'doc-cleared', ts: Date.now() }); } catch {}
    }

    function clearUiForNewDoc(message = 'Loading new documentâ€¦') {
      try {
        tableBody.innerHTML = '<tr><td colspan="5" class="empty">Loadingâ€¦</td></tr>';
        formMount.innerHTML = '<div class="empty">No schema found.</div>';
        payloadEl.value = '';
        previewStatus.textContent = '';
        if (headersTreeEl) headersTreeEl.innerHTML = '<div class="empty">No headings.</div>';
        btnSave.disabled = true; btnExport.disabled = true; btnSaveFromPreview.disabled = true;
        permNote.style.display = 'none';
        setStatus(message);
      } catch {}
      gSchema = { title: 'Form', fields: [] };
      gValues = {};
      gDirty = false;
      adoptHeadingBaseline({ flat: [], tree: [] });
    }

    async function hardResetDocContext(reason = '') {
      const tr = TRACE('hardResetDocContext:start', { reason, docId: gDocId });
      try {
        if (gDocId) {
          await window.formSuitePersist?.saveState?.(gDocId, {});
          try { await window.formSuitePersist?.putBytes?.(gDocId, new Uint8Array()); } catch (e) { tr.warn('putBytes failed', e); }
        }
      } catch (e) { tr.error('saveState failed', e); }
      gArrayBuffer = null; gFileHandle = null; gFileName = null; gDocId = null; gSDTs = [];
      adoptHeadingBaseline({ flat: [], tree: [] });
      clearActiveMeta();
      try {
        tableBody.innerHTML = '<tr><td colspan="5" class="empty">No document loaded.</td></tr>';
        formMount.innerHTML = '<div class="empty">No schema found.</div>';
        payloadEl.value = '';
        previewStatus.textContent = '';
        btnSave.disabled = true; btnExport.disabled = true; btnSaveFromPreview.disabled = true;
        permNote.style.display = 'none';
        setStatus(reason ? `Cleared: ${reason}` : 'Cleared.');
      } catch (e) { tr.warn('DOM reset failed', e); }
      try { if (headersTreeEl) headersTreeEl.innerHTML = '<div class="empty">No headings.</div>'; } catch {}
      tr.end('reset complete');
    }

    // --- Broadcast listeners (legacy + canonical) ---
    bcLegacy?.addEventListener?.('message', async (ev) => {
      const tr = TRACE('BroadcastChannel(legacy):message', ev?.data);
      try {
        const m = ev.data || {};
        if (m.type === 'doc-switched' && m.docId && m.docId !== gDocId) {
          clearUiForNewDoc('Switching to another documentâ€¦');
          let bytes = await window.formSuitePersist.getBytes?.(m.docId) || await window.formSuitePersist.getCurrentDocBytes?.();
          if (!bytes) { await hardResetDocContext('no bytes / no permission'); return; }
          gArrayBuffer = bytes.buffer ?? bytes;
          gFileName = m.name || gFileName;
          gDocId = m.docId;
          await renderFromCurrentBytes('(switched by other tab) ');
          await updateWriteAccessBanner();
        }
        if (m.type === 'doc-updated' && m.docId && m.docId === gDocId) {
          let bytes = await window.formSuitePersist.getBytes?.(gDocId) || await window.formSuitePersist.getCurrentDocBytes?.();
          if (!bytes) { await hardResetDocContext('no bytes / no permission'); return; }
          gArrayBuffer = bytes.buffer ?? bytes;
          await renderFromCurrentBytes('(updated by other tab) ');
          await updateWriteAccessBanner();
        }
        if (m.type === 'schema-updated' && m.docId && m.docId === gDocId) {
          gLastSchemaPushTs = m.ts || Date.now();
          const st = await window.formSuitePersist.loadState(gDocId);
          adoptHeadingBaseline({
            flat: Array.isArray(st?.headingsFlat) ? st.headingsFlat : Array.isArray(st?.headings) ? st.headings : [],
            tree: Array.isArray(st?.headingsTree) ? st.headingsTree : []
          });
          if (st?.schema) {
            const domVals = collectFormValues(st.schema);
            const wsVals  = st.values || {};
            gSchema = st.schema;
            gValues = { ...wsVals, ...domVals };
            buildForm(formMount, gSchema, gValues);
            await updatePreview(gValues);
            await debugLogExtractor('bc:rules-updated', { function:'BC rules-updated', from: 'rules.html' });
            setStatus('Schema updated from Form Builder.');
          }
        }
        if (m.type === 'doc-cleared') {
          await hardResetDocContext('cleared by another tab');
        }
      } finally { tr.end(); }
    });

    bcCanon?.addEventListener?.('message', async (ev) => {
      const tr = TRACE('BroadcastChannel(canon):message', ev?.data);
      try {
        const m = ev.data || {};
        if (m.type === 'active:set') {
          if (m.docId && m.docId !== gDocId) {
            clearUiForNewDoc('Switching to another documentâ€¦');
            let bytes = await window.formSuitePersist.getBytes?.(m.docId) || await window.formSuitePersist.getCurrentDocBytes?.();
            if (!bytes) { await hardResetDocContext('no bytes / no permission'); return; }
            gArrayBuffer = bytes.buffer ?? bytes;
            gFileName = m.name || gFileName;
            gDocId = m.docId;
            await renderFromCurrentBytes('(switched by other tab) ');
            await updateWriteAccessBanner();
          }
        }
        if (m.type === 'active:updated' && m.docId && m.docId === gDocId) {
          let bytes = await window.formSuitePersist.getBytes?.(gDocId) || await window.formSuitePersist.getCurrentDocBytes?.();
          if (!bytes) return;
          gArrayBuffer = bytes.buffer ?? bytes;
          await renderFromCurrentBytes('(updated by other tab) ');
        }
        if (m.type === 'active:clear') await hardResetDocContext('cleared by another tab');
      } finally { tr.end(); }
    });

    // --- Storage listeners (canonical first, legacy as fallback) ---
    window.addEventListener('storage', async (e) => {
      const tr = TRACE('storage:event', { key:e.key, newValue: !!e.newValue });
      try {
        if ((e.key === ACTIVE_LS_KEY || e.key === META_LS_KEY) && e.newValue) {
          const meta = JSON.parse(e.newValue || 'null');
          if (!meta?.docId || meta.docId === gDocId) return;
          clearUiForNewDoc('Switching to another documentâ€¦');
          let bytes = await window.formSuitePersist.getBytes?.(meta.docId) || await window.formSuitePersist.getCurrentDocBytes?.();
          if (!bytes) { await hardResetDocContext('no bytes / no permission'); return; }
          gArrayBuffer = bytes.buffer ?? bytes;
          gFileName = meta.name || gFileName;
          gDocId = meta.docId;
          await renderFromCurrentBytes('(switched by other tab) ');
          await updateWriteAccessBanner();
        }
      } finally { tr.end(); }
    });

    // =========================
    // STABLE FOREGROUND REFRESH
    // =========================
    let __fgRefreshLock = false;
    async function safeGetBytes(docId) {
      const tr = TRACE('safeGetBytes', { docId });
      try {
        let bytes = await window.formSuitePersist.getBytes?.(docId);
        if (bytes) { tr.end({ src:'opfs', len: bytes.byteLength || bytes.length }); return bytes; }

        bytes = await window.formSuitePersist.getCurrentDocBytes?.();
        if (bytes) { tr.end({ src:'currentDocBytes', len: bytes.byteLength || bytes.length }); return bytes; }

        const h = await window.formSuitePersist.getHandle?.(docId);
        if (h?.getFile) {
          try {
            const f = await h.getFile();
            bytes = await f.arrayBuffer();
            tr.end({ src:'handle.getFile', len: bytes.byteLength || bytes.length });
            return bytes;
          } catch (e) { tr.warn('handle.getFile failed', e); }
        }

        tr.end({ src:'none' });
        return null;
      } catch (e) { tr.error('safeGetBytes failed', e); tr.end(); return null; }
    }

    async function rehydrateOnForeground(source) {
      const tr = TRACE('rehydrateOnForeground', { source, docId: gDocId, locked: __fgRefreshLock });
      if (__fgRefreshLock) { tr.step('locked; skip'); tr.end(); return; }
      __fgRefreshLock = true;
      try {
        if (!gDocId) { tr.step('no docId'); return; }

        await new Promise(r => setTimeout(r, 120));

        let bytes = await safeGetBytes(gDocId);
        if (!bytes) {
          await new Promise(r => setTimeout(r, 120));
          bytes = await safeGetBytes(gDocId);
        }

        if (bytes) {
          gArrayBuffer = bytes.buffer ?? bytes;
          await renderFromCurrentBytes(`(${source} refreshed) `);
          await updateWriteAccessBanner();
          tr.end('refreshed');
          return;
        }

        if (gArrayBuffer?.byteLength) {
          setStatus(`Refresh skipped (${source}): no bytes yet; keeping current.`);
          await updateWriteAccessBanner();
          tr.end('kept current buffer');
          return;
        }

        const h = await window.formSuitePersist.getHandle?.(gDocId);
        if (h) {
          setStatus(`Refresh postponed (${source}): handle exists; waiting for bytes.`);
          await updateWriteAccessBanner();
          tr.end('postponed; has handle');
          return;
        }

        await hardResetDocContext('lost access');
        tr.end('hard reset');
      } catch (e) {
        tr.error('rehydrate failed', e);
      } finally {
        __fgRefreshLock = false;
      }
    }

    document.addEventListener('visibilitychange', () => {
      if (document.visibilityState === 'visible') rehydrateOnForeground('visible');
    });
    window.addEventListener('focus', () => {
      rehydrateOnForeground('focus');
    });

    // =========================
    // âœ… WRITE ACCESS BANNER / PROMPT
    // =========================
    async function updateWriteAccessBanner({ tryPrompt = false } = {}) {
      const tr = TRACE('updateWriteAccessBanner', { tryPrompt, docId: gDocId, supportsFS });
      try {
        if (!supportsFS || !gDocId) { permNote.style.display = 'none'; tr.end('unsupported/no-doc'); return 'unsupported'; }

        let handle = gFileHandle || await window.formSuitePersist.getHandle?.(gDocId);
        if (!handle || !handle.queryPermission) { permNote.style.display = 'none'; tr.end('no-handle'); return 'no-handle'; }

        let p = await handle.queryPermission({ mode: 'readwrite' });
        tr.step('queryPermission', p);

        if (p !== 'granted' && tryPrompt) {
          try {
            const r = await handle.requestPermission({ mode: 'readwrite' });
            p = r || p;
            tr.step('requestPermission', r);
          } catch (e) {
            tr.warn('requestPermission failed', e);
          }
        }

        permNote.style.display = (p === 'granted') ? 'none' : 'block';
        if (p === 'granted') gFileHandle = handle;

        tr.end({ final: p });
        return p || 'denied';
      } catch (e) {
        tr.error('updateWriteAccessBanner failed', e);
        permNote.style.display = 'block';
        return 'error';
      }
    }

    function installRulesUpdatedListener() {
      // attach once
      if (window.__fsRulesBCInstalled) {
        console.log('[Extractor][BC] listener already installed');
        return;
      }
      window.__fsRulesBCInstalled = true;

      console.log('[Extractor][BC] installing listeners', {
        hasCanon: !!bcCanon, hasLegacy: !!bcLegacy, gDocIdAtInstall: gDocId
      });

      const pickActiveMeta = () => {
        try {
          const v = localStorage.getItem('FS_ACTIVE_DOC_META') || localStorage.getItem('FS_CURRENT_DOC_META');
          return v ? JSON.parse(v) : null;
        } catch { return null; }
      };

      const onMsg = async (label, ev) => {
        const m = ev?.data || {};
        if (!m || typeof m !== 'object') return;

        // Always log incoming broadcasts for debugging
        console.log(`[Extractor][BC:${label}]`, m, 'local gDocId=', gDocId);

        if (m.type === 'rules-updated') {
          // Accept the docId from the message if we're not bound yet
          const targetId = m.docId || pickActiveMeta()?.docId || gDocId;
          if (!targetId) { console.warn('[Extractor][BC] rules-updated but no targetId'); return; }

          if (!gDocId) {
            // late-bind this tab to the active doc so we donâ€™t miss future changes
            gDocId = targetId;
            persistActiveMeta({ docId: gDocId, name: pickActiveMeta()?.name || gFileName || 'document' });
            console.log('[Extractor][BC] late-bound to docId', gDocId);
          }
          if (gDocId !== targetId) {
            console.log('[Extractor][BC] rules-updated for different doc; ignoring', { targetId, gDocId });
            return;
          }

          try {
            await updatePreview(collectFormValues(gSchema));
            await debugLogExtractor('bc:rules-updated', { function:'BC rules-updated', from: 'rules.html' });
            setStatus('Rules updated from Rules tab (BC).');
          } catch (e) {
            console.warn('[Extractor][BC] updatePreview failed after rules-updated', e);
          }
        }

        // (optional) react to generic state signal if your persistence emits it
        if (m.type === 'state-updated') {
          const active = pickActiveMeta();
          if (!active?.docId) return;
          if (!gDocId) gDocId = active.docId;
          if (gDocId !== active.docId) return;
          try {
            await updatePreview(collectFormValues(gSchema));
            await debugLogExtractor('bc:state-updated', { function:'BC state-updated' });
            setStatus('State updated (BC).');
          } catch (e) {
            console.warn('[Extractor][BC] updatePreview failed after state-updated', e);
          }
        }
      };

      bcCanon?.addEventListener?.('message', onMsg.bind(null, 'fs-active-doc'));
      bcLegacy?.addEventListener?.('message', onMsg.bind(null, 'form-suite-doc'));
      console.log('[Extractor][BC] listeners attached');
    }

    (async function setupRulesWatchdog(){
      let lastRV = null;

      async function tick() {
        try {
          if (!gDocId) {
            const meta = readActiveMeta();
            if (meta?.docId) {
              gDocId = meta.docId;
              console.log('[Extractor][Watchdog] late-bound gDocId from active meta', gDocId);
            } else {
              return; // still nothing to watch
            }
          }
          const st = await window.formSuitePersist.loadState(gDocId);
          const rv = st?.rulesVersion
            ?? st?.payload?.CRONOS_PAYLOAD?.rulesVersion
            ?? st?.CRONOS_PAYLOAD?.rulesVersion
            ?? st?.cronos_payload?.rulesVersion
            ?? null;

          if (rv !== lastRV) {
            console.log('[Extractor][Watchdog] rulesVersion changed:', { prev: lastRV, next: rv });
            lastRV = rv;
            await updatePreview(collectFormValues(gSchema));
            await debugLogExtractor('watchdog:rulesVersion', { function:'Watchdog', prev: (lastRV ?? null), next: rv });
            setStatus('Rules updated (poll).');
          }
        } catch (e) {
          console.warn('[Extractor][Watchdog] tick failed', e);
        }
      }

      setInterval(tick, 1500);
      console.log('[Extractor][Watchdog] installed');
    })();

    // =========================
    // TAG MAP / PREVIEW HELPERS
    // =========================

        // ---------- Common helpers ----------
    function __slug(s) {
      return String(s ?? '')
        .normalize('NFKD').replace(/[\u0300-\u036f]/g,'')
        .replace(/[^a-z0-9]+/gi,'_')
        .replace(/^_+|_+$/g,'')
        .toLowerCase();
    }

    function __resolveFieldRef(schema, ref) {
      if (!ref) return null;
      const id = String(ref);
      const fields = Array.isArray(schema?.fields) ? schema.fields : [];
      // by exact id
      let f = fields.find(x => String(x.id) === id);
      if (f) return f;
      // by label slug
      const s = __slug(id);
      f = fields.find(x => __slug(x.label || x.id) === s);
      return f || null;
    }

    // If the "when" field is a multichoice/select and the author wrote:
    //   when "Field: Option" equals true
    // â€¦we keep the rule untouched for persistence. This helper only
    // ensures a consistent shape for in-memory evaluation (no pruning!).
    function __coerceRuleForMultichoiceOption(schema, rule, whenField) {
      if (!whenField) return rule;
      const type = whenField.type;
      if (!['multichoice','select'].includes(type)) return rule;

      // keep authoring intact â€” just ensure "values" is an array
      const r = { ...rule };
      if (!Array.isArray(r.values)) r.values = [r.values];

      // nothing else is coerced here; evaluation layer should interpret:
      // if op==="equals" && values includes true => check option(s) in targets
      return r;
    }


    // ---------- Rules pruning against schema (NEW) ----------
    function getValidFieldIdSet(schema) {
      return new Set((schema?.fields || []).map(f => String(f.id)));
    }

    function normalizeRuleCollection(raw) {
      if (raw == null) return [];
      if (Array.isArray(raw)) {
        const acc = [];
        for (const item of raw) acc.push(...normalizeRuleCollection(item));
        return acc;
      }
      if (raw instanceof Set) return normalizeRuleCollection([...raw]);
      if (typeof raw === 'string') {
        const trimmed = raw.trim();
        if (!trimmed) return [];
        try {
          const parsed = JSON.parse(trimmed);
          return normalizeRuleCollection(parsed);
        } catch {
          return [];
        }
      }
      if (typeof raw === 'object') {
        const maybeRule = raw;
        if (maybeRule && (maybeRule.action || maybeRule.fieldId || maybeRule.whenField || maybeRule.targets)) {
          return [maybeRule];
        }
        const vals = [];
        for (const value of Object.values(maybeRule)) {
          vals.push(...normalizeRuleCollection(value));
        }
        return vals;
      }
      return [];
    }

    function dedupeRules(arr) {
      const seen = new Set();
      const res = [];
      for (const r of (arr || [])) {
        if (!r) continue;
        const shallow = (r && typeof r === 'object') ? { ...r } : r;
        if (shallow && typeof shallow === 'object') {
          delete shallow.version;
          delete shallow.ts;
        }
        const key = JSON.stringify(shallow ?? {});
        if (!seen.has(key)) {
          seen.add(key);
          res.push(r);
        }
      }
      return res;
    }

    // Collect rules from workspace state regardless of where the Rules tab put them
    function extractRulesFromState(state) {
      const out = { rules: [], fieldRules: [], meta: { rulesSources: [], fieldRuleSources: [] } };
      if (!state || typeof state !== 'object') return out;

      const payload =
            state?.payload?.CRONOS_PAYLOAD ? state.payload.CRONOS_PAYLOAD
          : state?.CRONOS_PAYLOAD         ? state.CRONOS_PAYLOAD
          : state?.cronos_payload         ? state.cronos_payload
          : state?.payload                ? state.payload
          : {};

      const ruleSources = [
        ['workspace.rules', normalizeRuleCollection(state?.rules)],
        ['payload.CRONOS_PAYLOAD.rules', normalizeRuleCollection(payload?.rules)],
        ['payload.rules', normalizeRuleCollection(state?.payload?.rules)],
        ['CRONOS_RULES', normalizeRuleCollection(state?.CRONOS_RULES)],
        ['cronos_rules', normalizeRuleCollection(state?.cronos_rules)],
      ];

      const fieldRuleSources = [
        ['workspace.fieldRules', normalizeRuleCollection(state?.fieldRules)],
        ['payload.CRONOS_PAYLOAD.fieldRules', normalizeRuleCollection(payload?.fieldRules)],
        ['payload.fieldRules', normalizeRuleCollection(state?.payload?.fieldRules)],
        ['CRONOS_FIELD_RULES', normalizeRuleCollection(state?.CRONOS_FIELD_RULES)],
        ['cronos_field_rules', normalizeRuleCollection(state?.cronos_field_rules)],
      ];

      out.rules = dedupeRules(ruleSources.flatMap(([, arr]) => arr));
      out.fieldRules = dedupeRules(fieldRuleSources.flatMap(([, arr]) => arr));
      out.meta.rulesSources = ruleSources.filter(([, arr]) => arr.length > 0).map(([name]) => name);
      out.meta.fieldRuleSources = fieldRuleSources.filter(([, arr]) => arr.length > 0).map(([name]) => name);

      return out;
    }

    function hasOwn(obj, key) {
      return !!obj && Object.prototype.hasOwnProperty.call(obj, key);
    }

    function resolveRulesForState(state, payloadOverride = null) {
      const view = state && typeof state === 'object' ? { ...state } : {};
      if (payloadOverride) {
        view.payload = { ...(state?.payload || {}), CRONOS_PAYLOAD: payloadOverride };
        view.CRONOS_PAYLOAD = payloadOverride;
        view.cronos_payload = payloadOverride;
      }

      const aggregated = extractRulesFromState(view);
      const wsRulesRaw = hasOwn(view, 'rules') ? normalizeRuleCollection(view.rules) : [];
      const wsFieldRulesRaw = hasOwn(view, 'fieldRules') ? normalizeRuleCollection(view.fieldRules) : [];

      const rules = hasOwn(view, 'rules') ? dedupeRules(wsRulesRaw) : aggregated.rules;
      const fieldRules = hasOwn(view, 'fieldRules') ? dedupeRules(wsFieldRulesRaw) : aggregated.fieldRules;

      const source = {
        rules: hasOwn(view, 'rules') ? 'workspace.rules' : (aggregated.meta?.rulesSources?.[0] || 'none'),
        fieldRules: hasOwn(view, 'fieldRules') ? 'workspace.fieldRules' : (aggregated.meta?.fieldRuleSources?.[0] || 'none'),
        contributingRules: aggregated.meta?.rulesSources || [],
        contributingFieldRules: aggregated.meta?.fieldRuleSources || []
      };

      return { rules, fieldRules, source };
    }

    // --- schema indexers / normalizers for rules ---
    function __buildSchemaIndex(schema) {
      const idx = { byId: new Map(), byLabel: new Map(), optionToField: new Map() };
      for (const f of (schema?.fields || [])) {
        const id = String(f.id);
        idx.byId.set(id, f);
        if (f.label) idx.byLabel.set(String(f.label).trim().toLowerCase(), f);

        const opts = [];
        if (Array.isArray(f.options)) {
          for (const o of f.options) {
            const label = (o?.label ?? o?.text ?? o?.value ?? o);
            if (label != null) opts.push(String(label));
          }
        }
        if (f.mc?.groups) {
          for (const g of f.mc.groups) {
            for (const it of (g.items || [])) {
              if (it?.value != null) opts.push(String(it.value));
            }
          }
        }
        for (const label of opts) idx.optionToField.set(label.trim().toLowerCase(), f);
      }
      return idx;
    }

    function __resolveFieldRef(schema, raw) {
      if (!raw) return null;
      const s = String(raw).trim();
      const idx = __buildSchemaIndex(schema);

      // option synth ids like "fieldId__opt__slug"
      if (s.includes('__opt__')) {
        const baseId = s.split('__opt__')[0];
        if (idx.byId.has(baseId)) return idx.byId.get(baseId);
        const slug = s.split('__opt__').pop();
        for (const [labelLower, field] of idx.optionToField.entries()) {
          const labelSlug = labelLower
            .normalize('NFKD').replace(/[\u0300-\u036f]/g,'')
            .replace(/[^a-z0-9]+/gi,'_').replace(/^_+|_+$/g,'')
            .toLowerCase();
          if (labelSlug === String(slug).toLowerCase()) return field;
        }
      }

      if (idx.byId.has(s)) return idx.byId.get(s);
      const byLabel = idx.byLabel.get(s.toLowerCase());
      if (byLabel) return byLabel;

      const parts = s.split(':').map(x => x.trim());
      if (parts.length >= 1) {
        const tryLabel = idx.byLabel.get(parts[0].toLowerCase());
        if (tryLabel) return tryLabel;
      }

      const own = idx.optionToField.get(s.toLowerCase());
      if (own) return own;

      console.warn('[resolveFieldRef] could not resolve field for:', s, {
        schemaFields: (schema?.fields || []).map(f => f.id),
        sampleField: schema?.fields?.[0]
      });
      return null;
    }

    function adoptHeadingBaseline(baseline) {
      const flat = baseline?.flat
        ? Array.isArray(baseline.flat) ? baseline.flat.slice() : []
        : Array.isArray(baseline) ? baseline.slice()
        : Array.isArray(baseline?.headings) ? baseline.headings.slice()
        : [];
      const tree = baseline?.tree
        ? (Array.isArray(baseline.tree) ? baseline.tree.slice() : [])
        : Array.isArray(baseline?.headingsTree) ? baseline.headingsTree.slice()
        : [];
      gHeadingBaseline = { flat, tree };
    }

    function buildHeadingTargetIndex(baseline) {
      const flat = Array.isArray(baseline?.flat)
        ? baseline.flat
        : Array.isArray(baseline) ? baseline
        : Array.isArray(baseline?.headings) ? baseline.headings
        : [];
      const tree = Array.isArray(baseline?.tree)
        ? baseline.tree
        : Array.isArray(baseline?.headingsTree) ? baseline.headingsTree
        : [];

      const byIdx = new Map();
      const byUid = new Map();
      const byComposite = new Map();
      const byNumber = new Map();

      const normComposite = (entry) => {
        const idx = Number(entry?.idx ?? entry?.key);
        const text = entry?.text || entry?.title || entry?.label || '';
        const num = entry?.number || entry?.num;
        if (num) return `${String(num)}|${text}`.trim();
        if (Number.isFinite(idx)) return `${idx + 1}|${text}`.trim();
        return text ? `|${text}` : '';
      };

      const add = (entry) => {
        if (!entry) return;
        const idx = Number(entry.idx ?? entry.key);
        if (Number.isFinite(idx) && !byIdx.has(idx)) byIdx.set(idx, entry);
        const uid = entry.uid || entry.id;
        if (uid && !byUid.has(String(uid))) byUid.set(String(uid), entry);
        const num = entry.number || entry.num;
        if (num && !byNumber.has(String(num))) byNumber.set(String(num), entry);
        const composite = entry.compositeKey || normComposite(entry);
        if (composite) {
          if (!byComposite.has(composite)) byComposite.set(composite, entry);
          // also index by number-only portion for lookups like "1.2"
          const head = composite.split('|', 1)[0];
          if (head && !byNumber.has(head)) byNumber.set(head, entry);
        }
      };

      flat.forEach(add);

      const walk = (nodes) => {
        if (!Array.isArray(nodes)) return;
        nodes.forEach((n) => {
          add(n);
          if (Array.isArray(n.children) && n.children.length) walk(n.children);
        });
      };
      walk(tree);

      const parseLegacyIdx = (target) => {
        const raw = (target && typeof target === 'object')
          ? (target.key ?? target.idx ?? target.id ?? target.number ?? target.uid ?? null)
          : target;
        if (raw == null) return NaN;
        if (typeof raw === 'number') return Number.isFinite(raw) ? raw : NaN;
        const str = String(raw).trim();
        if (!str) return NaN;
        if (/^\d+$/.test(str)) return Number(str);
        if (str.includes('|')) {
          const head = str.split('|', 1)[0];
          if (/^\d+$/.test(head)) return Number(head);
        }
        return NaN;
      };

      const resolve = (target) => {
        if (target && typeof target === 'object') {
          if (target.uid && byUid.has(String(target.uid))) return byUid.get(String(target.uid));
          if (target.idx != null) {
            const idx = Number(target.idx);
            if (Number.isFinite(idx)) {
              if (byIdx.has(idx)) return byIdx.get(idx);
              const legacy = idx - 1;
              if (byIdx.has(legacy)) {
                const maybe = byIdx.get(legacy);
                if (maybe && idx === Number(maybe.idx) + 1) return maybe;
              }
            }
          }
          if (target.key != null) {
            const idx = Number(target.key);
            if (Number.isFinite(idx)) {
              if (byIdx.has(idx)) return byIdx.get(idx);
              const legacy = idx - 1;
              if (byIdx.has(legacy)) {
                const maybe = byIdx.get(legacy);
                if (maybe && idx === Number(maybe.idx) + 1) return maybe;
              }
            }
            const keyStr = String(target.key);
            if (byComposite.has(keyStr)) return byComposite.get(keyStr);
            if (byNumber.has(keyStr)) return byNumber.get(keyStr);
          }
          if (target.label) {
            const lbl = String(target.label);
            const head = lbl.split(' ')[0];
            if (byNumber.has(head)) return byNumber.get(head);
          }
        }

        const rawStr = String((target && typeof target === 'object')
          ? (target.key ?? target.idx ?? target.id ?? target.uid ?? target.number ?? '')
          : target ?? '').trim();

        if (rawStr) {
          if (byComposite.has(rawStr)) return byComposite.get(rawStr);
          if (byUid.has(rawStr)) return byUid.get(rawStr);
          if (byNumber.has(rawStr)) return byNumber.get(rawStr);
          if (rawStr.includes('|')) {
            const head = rawStr.split('|', 1)[0];
            if (byNumber.has(head)) return byNumber.get(head);
            const num = Number(head);
            if (Number.isFinite(num)) {
              if (byIdx.has(num)) return byIdx.get(num);
              const legacy = num - 1;
              if (byIdx.has(legacy)) {
                const maybe = byIdx.get(legacy);
                if (maybe && num === Number(maybe.idx) + 1) return maybe;
              }
            }
          }
          const num = Number(rawStr);
          if (Number.isFinite(num)) {
            if (byIdx.has(num)) return byIdx.get(num);
            const legacy = num - 1;
            if (byIdx.has(legacy)) {
              const maybe = byIdx.get(legacy);
              if (maybe && num === Number(maybe.idx) + 1) return maybe;
            }
          }
        }
        return null;
      };

      const resolveIdx = (target) => {
        const entry = resolve(target);
        if (entry && Number.isFinite(Number(entry.idx))) return Number(entry.idx);
        const legacy = parseLegacyIdx(target);
        if (Number.isFinite(legacy)) {
          if (byIdx.has(legacy)) return legacy;
          const fallback = legacy - 1;
          if (byIdx.has(fallback)) {
            const maybe = byIdx.get(fallback);
            if (maybe && legacy === Number(maybe.idx) + 1) return Number(maybe.idx);
          }
          return legacy;
        }
        return NaN;
      };

      const buildLabel = (entry, fallback) => {
        if (!entry) return fallback || '';
        const text = entry.text || entry.title || entry.label || '';
        const num = entry.number || entry.num;
        if (num) return `${num} ${text}`.trim();
        if (text) return text;
        return fallback || '';
      };

      const normalizeTarget = (target) => {
        const entry = resolve(target);
        let idx = entry ? Number(entry.idx) : resolveIdx(target);
        if (!Number.isFinite(idx)) return null;

        if (!entry && target && typeof target === 'object') {
          const rawIdx = Number(target.idx ?? target.key);
          if (Number.isFinite(rawIdx)) {
            const legacy = rawIdx - 1;
            if (byIdx.has(legacy)) {
              const maybe = byIdx.get(legacy);
              if (maybe && rawIdx === Number(maybe.idx) + 1) {
                idx = Number(maybe.idx);
              }
            }
          }
        }

        const normalized = { key: idx, idx };
        if (entry?.uid) normalized.uid = entry.uid;
        else if (target && typeof target === 'object' && target.uid) normalized.uid = target.uid;
        const fallbackLabel = (target && typeof target === 'object') ? target.label : null;
        const label = buildLabel(entry, fallbackLabel) || `Heading ${idx + 1}`;
        normalized.label = label;
        const number = entry?.number || entry?.num;
        if (number) normalized.number = number;
        else normalized.number = String(idx + 1);
        return normalized;
      };

      return { resolve, resolveIdx, normalizeTarget, buildLabel };
    }

    function __coerceRuleForMultichoiceOption(schema, rule, field) {
      const out = JSON.parse(JSON.stringify(rule));
      const type = String(field?.type || '').toLowerCase();
      const baseId = String(field?.id ?? '');

      const setFieldRef = (id) => {
        if (!id) return;
        out.fieldId = id;
        if (out.field != null) out.field = id;
        if (out.whenField != null) out.whenField = id;
      };

      const ensureBooleanValues = (fallbackBool) => {
        const rawArr = Array.isArray(out.values)
          ? out.values.slice()
          : (out.values == null ? [] : [out.values]);
        let bool = null;
        if (rawArr.length) {
          const first = rawArr[0];
          if (typeof first === 'boolean') {
            bool = first;
          } else if (typeof first === 'string') {
            const norm = first.trim().toLowerCase();
            if (norm === 'true') bool = true;
            else if (norm === 'false') bool = false;
          }
        }
        if (bool == null) bool = fallbackBool;
        out.values = [bool];
        out.op = 'equals';
      };

      const optionCatalog = __buildOptionIndex(schema).get(baseId || '');
      const normalizeOptRef = (rawOptRef) => {
        if (!rawOptRef) return null;
        const [rawFieldPart, rawSlugPart] = rawOptRef.split('__opt__');
        const slugNorm = __slug(rawSlugPart || '');
        const resolvedFieldId = baseId || String(rawFieldPart || '').trim();
        if (!optionCatalog || !Array.isArray(optionCatalog.options) || !optionCatalog.options.length) {
          if (slugNorm) return `${resolvedFieldId}__opt__${slugNorm}`;
          return rawOptRef;
        }
        const hit = optionCatalog.options.find(o => o.slug === slugNorm)
          || optionCatalog.options.find(o => __slug(o.label) === slugNorm)
          || optionCatalog.options.find(o => __slug(o.value) === slugNorm);
        if (hit) return `${optionCatalog.id}__opt__${hit.slug}`;
        if (slugNorm) return `${optionCatalog.id}__opt__${slugNorm}`;
        return `${optionCatalog.id}__opt__${__slug(rawSlugPart || '')}`;
      };

      const matchOptionToken = (token) => {
        if (!optionCatalog || !token) return null;
        const normalized = __slug(token);
        return optionCatalog.options.find(o => o.slug === normalized)
            || optionCatalog.options.find(o => __slug(o.label) === normalized)
            || optionCatalog.options.find(o => __slug(o.value) === normalized)
            || null;
      };

      const rawRef = String(out.fieldId ?? out.field ?? out.whenField ?? '').trim();

      if (!['multichoice', 'select'].includes(type)) {
        if (!Array.isArray(out.values)) {
          out.values = out.values == null ? [] : [out.values];
        }
        if (baseId) setFieldRef(baseId);
        else if (rawRef) setFieldRef(rawRef);
        return out;
      }

      if (rawRef.includes('__opt__')) {
        const normalizedRef = normalizeOptRef(rawRef) || rawRef;
        setFieldRef(normalizedRef);
        const defaultBool = (() => {
          const arr = Array.isArray(out.values) ? out.values : (out.values == null ? [] : [out.values]);
          if (arr.length) {
            const first = arr[0];
            if (typeof first === 'boolean') return first;
            if (typeof first === 'string') {
              const norm = first.trim().toLowerCase();
              if (norm === 'true') return true;
              if (norm === 'false') return false;
            }
          }
          return true;
        })();
        ensureBooleanValues(defaultBool);
        return out;
      }

      let optionMatch = null;
      if (rawRef) {
        if (rawRef.includes(':')) {
          optionMatch = matchOptionToken(rawRef.split(':').pop());
        }
        if (!optionMatch) optionMatch = matchOptionToken(rawRef);
      }

      if (!optionMatch) {
        const valueTokens = Array.isArray(out.values)
          ? out.values.filter(v => typeof v === 'string' && v.trim())
          : (typeof out.values === 'string' && out.values.trim() ? [out.values] : []);
        if (valueTokens.length === 1) {
          optionMatch = matchOptionToken(valueTokens[0]);
        }
      }

      if (optionMatch) {
        const nextId = `${baseId}__opt__${optionMatch.slug}`;
        setFieldRef(nextId);
        const fallback = (() => {
          const arr = Array.isArray(out.values) ? out.values : (out.values == null ? [] : [out.values]);
          if (arr.length) {
            const first = arr[0];
            if (typeof first === 'boolean') return first;
            if (typeof first === 'string') {
              const norm = first.trim().toLowerCase();
              if (norm === 'true') return true;
              if (norm === 'false') return false;
            }
          }
          return String(out.op || '').toLowerCase() === 'notequals' ? false : true;
        })();
        ensureBooleanValues(fallback);
        return out;
      }

      if (!Array.isArray(out.values)) {
        out.values = out.values == null ? [] : [out.values];
      }

      if (baseId) setFieldRef(baseId);
      else if (rawRef) setFieldRef(rawRef);

      return out;
    }

    function normalizeHeadingsRulesForSchema(schema, rulesIn, headingBaseline = gHeadingBaseline) {
      const rules = Array.isArray(rulesIn) ? rulesIn : [];
      const out = [];
      const headingIndex = buildHeadingTargetIndex(headingBaseline);
      for (const raw of rules) {
        if (!raw) continue;

        const got = __resolveFieldRef(schema, raw.fieldId ?? raw.field ?? raw.whenField);
        if (!got) continue;

        const r0 = __coerceRuleForMultichoiceOption(schema, { ...raw }, got);

        const refAfterCoerce = r0?.fieldId ?? r0?.field ?? r0?.whenField;
        if (!__resolveFieldRef(schema, refAfterCoerce)) {
          const fallbackId = String(got.id);
          if (fallbackId) {
            r0.fieldId = fallbackId;
            if (r0.field != null) r0.field = fallbackId;
            if (r0.whenField != null) r0.whenField = fallbackId;
          }
        }

        // prune invalid condition field refs (if any)
        if (Array.isArray(r0.conditions)) {
          r0.conditions = r0.conditions.filter(c => {
            const ref = c?.fieldId ?? c?.leftFieldId ?? c?.rightFieldId;
            if (!ref) return false;
            return !!__resolveFieldRef(schema, ref);
          });
        }

        // HEADINGS: coerce targets to numeric keys only
        if (Array.isArray(r0.targets)) {
          r0.targets = r0.targets
            .map(t => headingIndex.normalizeTarget(t))
            .filter(Boolean);
        }

        out.push(r0);
      }
      return out;
    }

    // ---------- Helpers for robust field target resolution ----------
    function __slug(s) {
      return String(s ?? '')
        .normalize('NFKD').replace(/[\u0300-\u036f]/g,'')
        .replace(/[^a-z0-9]+/gi,'_')
        .replace(/^_+|_+$/g,'')
        .toLowerCase();
    }

    // Build: fieldId -> { id, label, type, options: [{value,label,slug}] }
    function __buildOptionIndex(schema) {
      const byField = new Map();
      for (const f of (schema?.fields || [])) {
        const rec = { id: String(f.id), label: String(f.label || f.id), type: f.type, options: [] };

        // (A) plain "options"
        if (Array.isArray(f.options)) {
          for (const opt of f.options) {
            const value = String(opt?.value ?? opt?.id ?? opt);
            const label = String(opt?.label ?? opt?.text ?? value);
            rec.options.push({ value, label, slug: __slug(label) });
          }
        }

        // (B) multi-choice groups
        if (f?.mc?.groups) {
          for (const g of f.mc.groups) {
            for (const it of (g.items||[])) {
              const value = String(it?.value ?? it?.id ?? it);
              const label = String(it?.label ?? it?.text ?? value);
              rec.options.push({ value, label, slug: __slug(label) });
            }
          }
        }

        byField.set(rec.id, rec);
      }
      return byField;
    }

    /**
     * Normalize FIELD rules ONLY (preserve option targets). Accepts targets as:
     *  - { id: "<fieldId>", optionValue, optionLabel, label? }
     *  - "fieldId" (parent field target)
     *  - "fieldId__opt__slug"
     *  - "Field Label: Option Label" (the UIâ€™s combined string)
     *  - { id: "fieldId", label: "Field Label: Option Label" } (legacy)
     */
    function normalizeFieldRulesForSchema(schema, rulesIn) {
      const rules = Array.isArray(rulesIn) ? rulesIn : [];
      const out = [];
      const optionIndex = __buildOptionIndex(schema);
      const fieldIndex  = new Map((schema?.fields || []).map(f => [String(f.id), f]));

      const dbg = []; // collect per-rule debug

      for (const raw of rules) {
        if (!raw) continue;

        // Resolve "when" field
        const resolvedField = __resolveFieldRef(schema, raw.fieldId ?? raw.field ?? raw.whenField);
        if (!resolvedField) {
          dbg.push({ id: raw.id, drop: 'unresolved whenField', raw });
          continue;
        }

        // Coerce condition if "looks like option" on multichoice/select
        const r0 = __coerceRuleForMultichoiceOption(schema, { ...raw }, resolvedField);

        const refAfterCoerce = r0?.fieldId ?? r0?.field ?? r0?.whenField;
        if (!__resolveFieldRef(schema, refAfterCoerce)) {
          const fallbackId = String(resolvedField.id);
          if (fallbackId) {
            r0.fieldId = fallbackId;
            if (r0.field != null) r0.field = fallbackId;
            if (r0.whenField != null) r0.whenField = fallbackId;
          }
        }

        // prune invalid condition refs
        if (Array.isArray(r0.conditions)) {
          r0.conditions = r0.conditions.filter(c => {
            const ref = c?.fieldId ?? c?.leftFieldId ?? c?.rightFieldId;
            return !!__resolveFieldRef(schema, ref);
          });
        }

        // === Robust TARGET normalization for FIELD rules ===
        const normTargets = [];
        const tIn = Array.isArray(r0.targets) ? r0.targets : [];
        const pf  = optionIndex.get(resolvedField.id); // parent field option catalog (if any)

        for (const t of tIn) {
          // 1) Already structured option target
          if (t && typeof t === 'object' && (t.optionValue != null || t.optionLabel != null)) {
            const id = String(t.id ?? resolvedField.id);
            const optVal = String(t.optionValue ?? '');
            const optLab = String(t.optionLabel ?? optVal);
            const parentLabel = fieldIndex.get(id)?.label || id;
            normTargets.push({
              id,
              optionValue: optVal,
              optionLabel: optLab,
              label: t.label || `${parentLabel}: ${optLab || optVal}`
            });
            continue;
          }

          // 2) String format
          if (typeof t === 'string') {
            const s = t.trim();

            // 2a) "fieldId__opt__slug"
            if (s.includes('__opt__')) {
              const [maybeId, slug] = s.split('__opt__');
              const id = String(maybeId);
              const cat = optionIndex.get(id) || pf;
              if (cat && cat.options?.length) {
                const hit = cat.options.find(o => o.slug === __slug(slug));
                if (hit) {
                  normTargets.push({
                    id: cat.id,
                    optionValue: hit.value,
                    optionLabel: hit.label,
                    label: `${cat.label}: ${hit.label}`
                  });
                  continue;
                }
              }
            }

            // 2b) "Field Label: Option Label" (with colon)
            if (s.includes(':')) {
              const [lhs, rhs] = s.split(':');
              const fieldLike = lhs.trim();
              const optLike   = rhs.trim();

              // Try resolve field by id first, then by label
              let cat = optionIndex.get(fieldLike);
              if (!cat) {
                // try label match
                for (const [_id, rec] of optionIndex.entries()) {
                  if (__slug(rec.label) === __slug(fieldLike)) { cat = rec; break; }
                }
              }
              // Fall back to the parent field
              if (!cat) cat = pf;

              if (cat && cat.options?.length) {
                const hit =
                  cat.options.find(o => __slug(o.label) === __slug(optLike)) ||
                  cat.options.find(o => __slug(o.value) === __slug(optLike));
                if (hit) {
                  normTargets.push({
                    id: cat.id,
                    optionValue: hit.value,
                    optionLabel: hit.label,
                    label: `${cat.label}: ${hit.label}`
                  });
                  continue;
                }
              }
            }

            // 2c) plain field id string (parent field target)
            if (fieldIndex.has(s)) {
              const parentLabel = fieldIndex.get(s)?.label || s;
              normTargets.push({ id: s, label: parentLabel });
              continue;
            }

            // 2d) plain option label string (implied current parent field)
            if (pf && pf.options?.length) {
              const hit =
                pf.options.find(o => __slug(o.label) === __slug(s)) ||
                pf.options.find(o => __slug(o.value) === __slug(s));
              if (hit) {
                normTargets.push({
                  id: pf.id,
                  optionValue: hit.value,
                  optionLabel: hit.label,
                  label: `${pf.label}: ${hit.label}`
                });
                continue;
              }
            }

            // Couldnâ€™t resolve â€” keep a readable fallback to avoid silent loss
            normTargets.push({ id: resolvedField.id, label: s });
            continue;
          }

          // 3) Object without optionValue â€” maybe {id,label}
          if (t && typeof t === 'object') {
            const id = String(t.id ?? resolvedField.id);
            const label = String(t.label ?? fieldIndex.get(id)?.label ?? id);
            normTargets.push({ id, label });
            continue;
          }

          // 4) Unknown / null â€” skip
        }

        // Attach normalized targets
        const rFinal = { ...r0, targets: normTargets };

        // Debug per rule
        dbg.push({
          id: rFinal.id,
          whenField: rFinal.fieldId,
          action: rFinal.action,
          op: rFinal.op,
          values: rFinal.values,
          inTargetsCount: tIn.length,
          outTargetsCount: normTargets.length,
          sampleOut: normTargets[0] || null
        });

        out.push(rFinal);
      }

      // One consolidated debug line (keeps console tidy)
      console.log('[normalizeFieldRulesForSchema][summary]', {
        rulesIn: rules.length,
        rulesOut: out.length,
        details: dbg
      });

      return out;
    }


    function normalizeForSchema(schema, values, tagMap) {
      const fieldIds = new Set((schema?.fields || []).map(f => String(f.id)));
      const prunedValues = {};
      for (const [k, v] of Object.entries(values || {})) {
        if (fieldIds.has(String(k))) prunedValues[k] = v;
      }
      const prunedTagMap = {};
      for (const [tag, fieldId] of Object.entries(tagMap || {})) {
        if (fieldIds.has(String(fieldId))) prunedTagMap[tag] = fieldId;
      }
      return { values: prunedValues, tagMap: prunedTagMap };
    }

    async function getTagMapFor(docId) {
      try {
        const state = docId ? (await window.formSuitePersist.loadState(docId)) : null;
        const tagMap = (state?.payload?.CRONOS_PAYLOAD?.tagMap)
                    || (state?.CRONOS_PAYLOAD?.tagMap)
                    || (state?.cronos_payload?.tagMap)
                    || (state?.tagMap)
                    || {};
        return tagMap;
      } catch {
        return {};
      }
    }

    function loadSchemaFromLocalStorage() {
      const tr = TRACE('loadSchemaFromLocalStorage');
      try { const s = JSON.parse(localStorage.getItem(STORAGE_KEY) || 'null'); tr.end({ has:s?.fields?.length }); return s; }
      catch (e) { tr.error('parse fail', e); tr.end(); return null; }
    }

    // Collect values from the live form (address values are structured)
    function collectFormValues(schema) {
      const form = document.getElementById('liveForm');
      const out = {};
      if (!form || !schema) return out;
      for (const f of (schema.fields || [])) {
        if (f.type === 'multichoice') {
          const nodes = form.querySelectorAll(`input[type="checkbox"][name="${CSS.escape(f.id)}"]`);
          out[f.id] = Array.from(nodes).filter(n => n.checked).map(n => n.value);
          continue;
        }
        if (f.type === 'address') {
          out[f.id] = __addressValues[f.id] ?? null;
          continue;
        }
        const el = form.elements[f.id];
        out[f.id] = el ? el.value : null;
      }
      return out;
    }
    // =========================
    // (REPLACE) updatePreview(values)
    // =========================
    async function updatePreview(values) {
      const tr = TRACE('updatePreview');
      try {
        if (!payloadEl) return;

        const wsState = gDocId ? (await window.formSuitePersist.loadState(gDocId)) : null;
        if (wsState) {
          adoptHeadingBaseline({
            flat: Array.isArray(wsState.headingsFlat) ? wsState.headingsFlat : Array.isArray(wsState.headings) ? wsState.headings : [],
            tree: Array.isArray(wsState.headingsTree) ? wsState.headingsTree : gHeadingBaseline.tree
          });
        }
        const payloadObj = wsState?.payload?.CRONOS_PAYLOAD
                        || wsState?.CRONOS_PAYLOAD
                        || wsState?.cronos_payload
                        || {};

        const { rules: mergedRulesRaw, fieldRules: mergedFieldRaw, source: ruleSourceMeta } =
          resolveRulesForState(wsState || {}, payloadObj);

        await debugLogExtractor('updatePreview:merge', {
          function: 'updatePreview',
          chosenRulesSource: ruleSourceMeta.rules,
          chosenFieldRulesSource: ruleSourceMeta.fieldRules,
          contributingRulesSources: ruleSourceMeta.contributingRules,
          contributingFieldRulesSources: ruleSourceMeta.contributingFieldRules,
          wsRules: normalizeRuleCollection(wsState?.rules).length,
          plRules: normalizeRuleCollection(payloadObj?.rules).length,
          wsFieldRules: normalizeRuleCollection(wsState?.fieldRules).length,
          plFieldRules: normalizeRuleCollection(payloadObj?.fieldRules).length
        });

        // Normalize against **current** gSchema (already set by renderFromCurrentBytes)
        const rules      = normalizeHeadingsRulesForSchema(gSchema, mergedRulesRaw, gHeadingBaseline);
        const fieldRules = normalizeFieldRulesForSchema(gSchema, mergedFieldRaw);

        // Instrument target survival for fieldRules
        console.log('[FieldRules][targets]', fieldRules.map(r => ({
          id: r.id, action: r.action, when: r.fieldId, op: r.op, values: r.values,
          targetsCount: Array.isArray(r.targets) ? r.targets.length : 0,
          sampleTarget: Array.isArray(r.targets) ? r.targets[0] : null
        })));

        const tagMapRaw = await getTagMapFor(gDocId);
        const { values: prunedValues, tagMap: prunedTagMap } =
          normalizeForSchema(gSchema, values || {}, tagMapRaw);

        const previewObj = {
          title:  gSchema?.title || 'Form',
          fields: gSchema?.fields || [],
          values: prunedValues,
          tagMap: prunedTagMap,
          rules,
          fieldRules
        };
        payloadEl.value = JSON.stringify(previewObj, null, 2);

        await debugLogExtractor('updatePreview:previewBuilt', {
          function:'updatePreview',
          previewLen: (payloadEl?.value || '').length
        });
      } finally {
        tr.end();
      }
    }


    let previewTimer = null;
    function schedulePreviewUpdate() {
      clearTimeout(previewTimer);
      previewTimer = setTimeout(async () => {
        const vals = collectFormValues(gSchema);
        if (gDocId) await window.formSuitePersist.saveState(gDocId, { schema: gSchema, values: vals });
        await updatePreview(vals);
        gDirty = true;
        setStatus('Unsaved changes â€” press Save to update DOCX.');
      }, 250);
    }

    function buildForm(container, schema, values) {
      const tr = TRACE('buildForm', { fields: schema?.fields?.length || 0 });
      try {
        container.innerHTML = '';
        if (!schema || !Array.isArray(schema.fields) || schema.fields.length === 0) {
          container.innerHTML = '<div class="empty">No manual schema. Create one in the Builder, or load a DOCX that already contains a payload schema.</div>';
          tr.end('empty schema');
          return;
        }

        const form = document.createElement('form');
        form.id = 'liveForm';
        form.noValidate = true;
        form.style.display = 'grid';
        form.style.gap = '12px';

        if (schema.title) {
          const h = document.createElement('h4');
          h.textContent = schema.title;
          h.style.margin = '0 0 6px';
          form.appendChild(h);
        }

        for (const f of schema.fields) {
          const w = TRACE('buildForm:field', f);
          const wrap = document.createElement('div');
          wrap.className = 'field';
          const label = document.createElement('label');
          label.htmlFor = f.id;
          label.textContent = f.label || f.id || '(field)';
          label.style.display = 'flex';
          label.style.justifyContent = 'space-between';
          label.style.alignItems = 'center';
          if (f.required) {
            const star = document.createElement('span');
            star.textContent = 'â€¢'; star.title = 'required'; star.style.fontWeight = '600'; star.style.color = '#ef4444';
            label.appendChild(star);
          }
          wrap.appendChild(label);

          let input;

          if (f.type === 'multichoice') {
            const box = document.createElement('div');
            box.style.display = 'grid'; box.style.gap = '6px';
            (f.options || []).forEach(opt => {
              const id = `${f.id}__${String(opt?.value ?? opt).replace(/\s+/g,'_')}`;
              const row = document.createElement('label');
              row.style.display = 'flex'; row.style.gap = '8px'; row.style.alignItems = 'center';
              const cb = document.createElement('input');
              cb.type = 'checkbox'; cb.name = f.id; cb.id = id; cb.value = String(opt?.value ?? opt);
              if (Array.isArray(values?.[f.id]) && values[f.id].includes(cb.value)) cb.checked = true;
              const span = document.createElement('span'); span.textContent = String(opt?.label ?? opt?.text ?? opt?.value ?? opt);
              row.appendChild(cb); row.appendChild(span); box.appendChild(row);
            });
            wrap.appendChild(box);
            box.addEventListener('change', schedulePreviewUpdate);
            form.appendChild(wrap);
            w.end();
            continue;

          } else if (f.type === 'select') {
            input = document.createElement('select');
            (f.options || []).forEach(opt => {
              const o = document.createElement('option');
              o.value = String(opt?.value ?? opt?.id ?? opt);
              o.textContent = String(opt?.label ?? opt?.text ?? opt?.value ?? opt);
              input.appendChild(o);
            });

          } else if (f.type === 'date') {
            input = document.createElement('input'); input.type = 'text'; input.dataset.type = 'date'; input.dataset.format = f.dateFormat || 'Y-m-d';

          } else if (f.type === 'address') {
            const mountDiv = document.createElement('div');
            mountDiv.className = 'address-field';
            wrap.appendChild(mountDiv);

            const initial =
              typeof values?.[f.id] === 'string'
                ? { formatted: values[f.id] }
                : (values?.[f.id] || null);

            __addressValues[f.id] = initial || null;

            try {
              AddressAuto.mount(mountDiv, {
                id: f.id,
                label: f.label || 'Address',
                required: !!f.required,
                value: initial || null,
                onChange: (val) => { __addressValues[f.id] = val; schedulePreviewUpdate(); }
              });
            } catch (err) {
              const fallback = document.createElement('input');
              fallback.type = 'text';
              fallback.id = f.id;
              fallback.name = f.id;
              fallback.placeholder = 'Address';
              if (initial?.formatted) fallback.value = initial.formatted;
              fallback.addEventListener('input', () => {
                __addressValues[f.id] = { formatted: fallback.value };
                schedulePreviewUpdate();
              });
              mountDiv.appendChild(fallback);
            }

            form.appendChild(wrap);
            w.end();
            continue;

          } else {
            input = document.createElement('input'); input.type = 'text';
          }

          input.id = f.id; input.name = f.id;
          if (f.required) input.required = true;
          if (values && values[f.id] != null) input.value = values[f.id];

          input.addEventListener('change', schedulePreviewUpdate);
          input.addEventListener('input', schedulePreviewUpdate);
          wrap.appendChild(input);

          if (f.type === 'date') {
            setTimeout(() => {
              const tt = TRACE('flatpickr:init', { id: input.id, format: input.dataset.format });
              try {
                if (window.flatpickr) {
                  window.flatpickr(input, {
                    dateFormat: input.dataset.format || 'Y-m-d',
                    allowInput: true,
                    onChange: schedulePreviewUpdate,
                    onValueUpdate: schedulePreviewUpdate
                  });
                }
              } finally { tt.end(); }
            }, 0);
          }

          form.appendChild(wrap);
          w.end();
        }

        container.appendChild(form);
        tr.end('form built');
      } catch (e) { tr.error('failed', e); tr.end(); }
    }

    // =========================
    // SDT PARSING (JS)
    // =========================
    const W_NS = "http://schemas.openxmlformats.org/wordprocessingml/2006/main";
    function xmlText(el) {
      let s = '';
      const rec = n => {
        if (!n) return;
        if (n.nodeType === 3) { s += n.nodeValue; return; }
        if (n.nodeType === 1) {
          const ln = n.localName;
          if (ln === 'p' || ln === 'cr' || ln === 'br') s += '\n';
          for (const ch of n.childNodes) rec(ch);
        }
      };
      rec(el);
      return s.replace(/\s+\n/g,'\n').replace(/\n{3,}/g,'\n\n').trim();
    }

    async function parseSDTs_JS(arrayBuffer) {
      const tr = TRACE('parseSDTs_JS', { hasBuffer: !!arrayBuffer, len: arrayBuffer?.byteLength });
      try {
        if (!arrayBuffer) return { sdts: [], scan: [], total: 0 };
        const zip = await JSZip.loadAsync(arrayBuffer);
        const parts = zip.file(/^word\/(?!_rels\/|theme\/|fontTable\.xml|styles\.xml|numbering\.xml|settings\.xml|webSettings\.xml).*\.xml$/i) || [];
        tr.step('parts', parts.map(p => p.name));
        const parser = new DOMParser();
        const sdts = [];
        const scan = [];
        for (const f of parts) {
          const pf = TRACE('parseSDTs_JS:file', f.name);
          const xmlTextContent = await f.async('string');
          let err = null, countBefore = sdts.length;
          try {
            const xml = parser.parseFromString(xmlTextContent, "application/xml");
            const found = Array.from(xml.getElementsByTagNameNS(W_NS, 'sdt'));
            for (const sdt of found) {
              const pr = sdt.getElementsByTagNameNS(W_NS, 'sdtPr')[0];
              const content = sdt.getElementsByTagNameNS(W_NS, 'sdtContent')[0] || sdt;
              let tag = '', alias = '';
              if (pr) {
                const tEl = pr.getElementsByTagNameNS(W_NS, 'tag')[0];
                if (tEl) tag = tEl.getAttributeNS(W_NS, 'val') || tEl.getAttribute('w:val') || '';
                const aEl = pr.getElementsByTagNameNS(W_NS, 'alias')[0];
                if (aEl) alias = aEl.getAttributeNS(W_NS, 'val') || aEl.getAttribute('w:val') || '';
              }
              sdts.push({ part: f.name.split('/').pop().replace('.xml',''), tag, alias, text: xmlText(content) });
            }
          } catch (e) { err = e?.message || String(e); pf.warn('xml parse error', e); }
          scan.push({ path: f.name, part: f.name.split('/').pop().replace('.xml',''), size: xmlTextContent.length, sdt_count: sdts.length - countBefore, error: err });
          pf.end({ added: sdts.length - countBefore, error: err });
        }
        tr.end({ total: sdts.length, scanned: scan.length });
        return { sdts, scan, total: sdts.length };
      } catch (e) { tr.error('failed', e); tr.end(); return { sdts: [], scan: [], total: 0 }; }
    }

        // =========================
    // PYODIDE (payload/SDT writes)
    // =========================
    let pyodideReady = (async () => {
      const tr = TRACE('pyodide:bootstrap');
      try {
        const s = document.createElement('script');
        s.src = "https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js";
        document.head.appendChild(s);
        await new Promise(r => s.onload = r);
        const py = await loadPyodide({ indexURL: "https://cdn.jsdelivr.net/pyodide/v0.24.1/full/" });
        tr.step('pyodide loaded');
        await py.runPythonAsync(`
import io, zipfile, json, re
import xml.etree.ElementTree as ET

_W_NS = "http://schemas.openxmlformats.org/wordprocessingml/2006/main"
def _q(local): return "{%s}%s" % (_W_NS, local)

# ---------------------- existing helpers ----------------------
def write_docvar(u8, var_name, value):
    data = bytes(u8); outbuf = io.BytesIO()
    with zipfile.ZipFile(io.BytesIO(data), "r") as zfin, zipfile.ZipFile(outbuf,"w",compression=zipfile.ZIP_DEFLATED) as zfout:
        try: names = set(zfin.namelist())
        except: names = set()
        if "word/settings.xml" in names:
            try: root = ET.fromstring(zfin.read("word/settings.xml"))
            except ET.ParseError: root = ET.Element(_q("settings"))
        else:
            root = ET.Element(_q("settings"))
        doc_vars = root.find(_q("docVars"))
        if doc_vars is None:
            doc_vars = ET.SubElement(root, _q("docVars"))
        target = None
        for dv in doc_vars.findall(_q("docVar")):
            if dv.get(_q("name")) == var_name:
                target = dv; break
        if target is None:
            target = ET.SubElement(doc_vars, _q("docVar"), {_q("name"): var_name, _q("val"): value})
        else:
            target.set(_q("val"), value)
        settings_bytes = ET.tostring(root, encoding="utf-8", xml_declaration=True)
        for n in zfin.namelist():
            if n == "word/settings.xml": continue
            zfout.writestr(n, zfin.read(n))
        zfout.writestr("word/settings.xml", settings_bytes)
    return outbuf.getvalue()

def read_docvar_settings(u8, var_name):
    data = bytes(u8)
    with zipfile.ZipFile(io.BytesIO(data), "r") as zf:
        try:
            xml = zf.read("word/settings.xml")
        except KeyError:
            return None
        try:
            root = ET.fromstring(xml)
        except ET.ParseError:
            return None
        W_NS = "http://schemas.openxmlformats.org/wordprocessingml/2006/main"
        def _q(local):
            return "{%s}%s" % (W_NS, local)
        doc_vars = root.find(_q("docVars"))
        if doc_vars is None:
            return None
        for dv in doc_vars.findall(_q("docVar")):
            if dv.get(_q("name")) == var_name:
                return dv.get(_q("val"))
    return None

def read_docvar_custom(u8, var_name):
    data = bytes(u8)
    name = str(var_name or "")
    with zipfile.ZipFile(io.BytesIO(data), "r") as zf:
        try:
            xml = zf.read("docProps/custom.xml")
        except KeyError:
            return None
        try:
            root = ET.fromstring(xml)
        except ET.ParseError:
            return None
        ns = {
            'cp': 'http://schemas.openxmlformats.org/officeDocument/2006/custom-properties',
            'vt': 'http://schemas.openxmlformats.org/officeDocument/2006/docPropsVTypes'
        }
        for prop in root.findall('cp:property', ns):
            if prop.get('name') == name:
                for child in list(prop):
                    if child.text is not None:
                        return child.text
    return None

def _set_sdt_text(content_el, value):
    texts = content_el.findall(".//w:t", {"w": _W_NS})
    if texts:
        first = True
        for t in texts:
            if first:
                t.text = value
                first = False
            else:
                t.text = ""
        return
    has_block = (content_el.find(".//w:p", {"w": _W_NS}) is not None) or (content_el.find(".//w:tbl", {"w": _W_NS}) is not None)
    for ch in list(content_el): content_el.remove(ch)
    if has_block:
        p = ET.SubElement(content_el, _q("p")); r = ET.SubElement(p, _q("r"))
    else:
        r = ET.SubElement(content_el, _q("r"))
    t = ET.SubElement(r, _q("t")); t.text = value
    if (value.strip() != value) or ("\\n" in value) or ("  " in value):
        t.set("{http://www.w3.org/XML/1998/namespace}space", "preserve")

def write_sdts_by_tag(u8, tag_to_text_json):
    try: mapping = json.loads(tag_to_text_json or "{}")
    except Exception: mapping = {}
    if not mapping: return u8
    data = bytes(u8); outbuf = io.BytesIO()
    with zipfile.ZipFile(io.BytesIO(data), "r") as zfin, zipfile.ZipFile(outbuf,"w",compression=zipfile.ZIP_DEFLATED) as zfout:
        names = zfin.namelist()
        def is_target(name):
            if not (name.startswith("word/") and name.endswith(".xml")): return False
            skip = {"word/styles.xml","word/numbering.xml","word/theme/theme1.xml","word/fontTable.xml","word/settings.xml","word/webSettings.xml"}
            return name not in skip and not name.startswith("word/_rels/")
        for n in names:
            if not is_target(n):
                zfout.writestr(n, zfin.read(n)); continue
            try:
                root = ET.fromstring(zfin.read(n))
            except ET.ParseError:
                zfout.writestr(n, zfin.read(n)); continue
            changed = False
            for sdt in root.findall(".//w:sdt", {"w": _W_NS}):
                pr = sdt.find("w:sdtPr", {"w": _W_NS})
                if pr is None: continue
                tag_el = pr.find("w:tag", {"w": _W_NS})
                tag_val = tag_el.get(_q("val")) if tag_el is not None else ""
                if not tag_val or tag_val not in mapping: continue
                content_el = sdt.find("w:sdtContent", {"w": _W_NS}) or sdt
                val = mapping.get(tag_val, "")
                if not isinstance(val, str):
                    try: val = json.dumps(val, ensure_ascii=False)
                    except Exception: val = str(val)
                _set_sdt_text(content_el, val); changed = True
            out_xml = ET.tostring(root, encoding="utf-8", xml_declaration=True) if changed else zfin.read(n)
            zfout.writestr(n, out_xml)
    return outbuf.getvalue()

# ---------- heading + block collectors ----------
_STYLE_HINT_PATTERNS = [
    re.compile(r"heading\s*([1-9])", re.IGNORECASE),
    re.compile(r"Ã¼berschrift\s*([1-9])", re.IGNORECASE),
    re.compile(r"titre\s*([1-9])", re.IGNORECASE),
    re.compile(r"t[iÃ­]tulo\s*([1-9])", re.IGNORECASE),
    re.compile(r"encabezado\s*([1-9])", re.IGNORECASE),
    re.compile(r"rubrik\s*([1-9])", re.IGNORECASE),
    re.compile(r"zagolovok\s*([1-9])", re.IGNORECASE),
    re.compile(r"Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº\s*([1-9])", re.IGNORECASE),
]

def _level_from_style_hint(value):
    if not value:
        return 0
    s = str(value).strip()
    if not s:
        return 0
    for pattern in _STYLE_HINT_PATTERNS:
        m = pattern.search(s)
        if m:
            try:
                return int(m.group(1))
            except Exception:
                return 0
    m2 = re.match(r"^heading([1-9])$", s, re.IGNORECASE)
    if m2:
        try:
            return int(m2.group(1))
        except Exception:
            return 0
    return 0

def _build_heading_style_map(zip_file):
    try:
        raw = zip_file.read("word/styles.xml")
    except KeyError:
        return {}
    try:
        root = ET.fromstring(raw)
    except ET.ParseError:
        return {}

    by_id = {}
    for style in root.findall("w:style", {"w": _W_NS}):
        st_type = (style.get(_q("type")) or style.get("type") or "").strip().lower()
        if st_type and st_type != "paragraph":
            continue
        style_id = style.get(_q("styleId")) or style.get("styleId") or ""
        if not style_id:
            continue
        name_el = style.find(_q("name"))
        name = ""
        if name_el is not None:
            name = name_el.get(_q("val")) or name_el.get("val") or ""
        based_on_el = style.find(_q("basedOn"))
        based_on = ""
        if based_on_el is not None:
            based_on = based_on_el.get(_q("val")) or based_on_el.get("val") or ""
        lvl = 0
        ppr = style.find(_q("pPr"))
        if ppr is not None:
            ol = ppr.find(_q("outlineLvl"))
            if ol is not None:
                val = ol.get(_q("val")) or ol.get("val")
                if val not in (None, ""):
                    try:
                        num = int(val)
                        if num >= 0:
                            lvl = max(1, min(9, num + 1))
                    except Exception:
                        pass
        if not lvl:
            lvl = _level_from_style_hint(style_id) or _level_from_style_hint(name)
        by_id[style_id] = {"basedOn": based_on or "", "rawLevel": int(lvl) if lvl else 0}

    resolved = {}

    def resolve(style_id, depth=0):
        if not style_id or style_id not in by_id or depth > 12:
            return 0
        if style_id in resolved:
            return resolved[style_id]
        info = by_id[style_id]
        lvl = info.get("rawLevel") or 0
        if lvl:
            resolved[style_id] = lvl
            return lvl
        parent = resolve(info.get("basedOn") or "", depth + 1)
        resolved[style_id] = parent or 0
        return resolved[style_id]

    for style_id in list(by_id.keys()):
        resolve(style_id)

    return resolved

def _heading_level_trace(p_el, style_map=None):
    ppr = p_el.find(_q("pPr"))
    if ppr is None:
        return (None, None)
    ol = ppr.find(_q("outlineLvl"))
    if ol is not None and ol.get(_q("val")) is not None:
        try:
            raw = int(ol.get(_q("val")))
            lvl = max(1, min(9, raw + 1))
            return (lvl, f"outlineLvl:{raw}")
        except Exception:
            pass
    ps = ppr.find(_q("pStyle"))
    if ps is not None:
        style_id = ps.get(_q("val")) or ps.get("val")
        if style_id:
            if style_map:
                lvl = style_map.get(style_id)
                if isinstance(lvl, int) and lvl > 0:
                    return (lvl, f"style:{style_id}")
            v = style_id.lower()
            if v.startswith("heading"):
                try:
                    lvl = int(v.replace("heading", "").strip())
                    if lvl > 0:
                        return (lvl, f"builtin:{style_id}")
                except Exception:
                    return (None, None)
    return (None, None)

def _heading_level(p_el, style_map=None):
    lvl, _ = _heading_level_trace(p_el, style_map)
    return lvl

def _iter_blocks_within(container, top_level, style_map=None):
    for node in list(container):
        if node.tag == _q("sdt"):
            inner = node.find(_q("sdtContent"))
            if inner is not None:
                yield from _iter_blocks_within(inner, top_level, style_map)
            else:
                yield {"element": node, "type": "other", "level": None, "top": top_level}
        elif node.tag == _q("p"):
            yield {"element": node, "type": "p", "level": _heading_level(node, style_map), "top": top_level}
        elif node.tag == _q("tbl"):
            yield {"element": node, "type": "tbl", "level": None, "top": top_level}
        else:
            yield {"element": node, "type": "other", "level": None, "top": top_level}

def _collect_body_blocks(body_el, style_map=None):
    blocks = []
    for child in list(body_el):
        if child.tag == _q("sdt"):
            content = child.find(_q("sdtContent"))
            if content is not None:
                blocks.extend(_iter_blocks_within(content, child, style_map))
            else:
                blocks.append({"element": child, "type": "other", "level": None, "top": child})
        elif child.tag == _q("p"):
            blocks.append({"element": child, "type": "p", "level": _heading_level(child, style_map), "top": child})
        elif child.tag == _q("tbl"):
            blocks.append({"element": child, "type": "tbl", "level": None, "top": child})
        else:
            blocks.append({"element": child, "type": "other", "level": None, "top": child})
    return blocks

def _paragraph_plain_text(p_el):
    if p_el is None:
        return ""
    parts = []
    for t in p_el.findall(".//w:t", {"w": _W_NS}):
        if t.text:
            parts.append(t.text)
    return "".join(parts)

def inspect_export_removal_plan(u8, idx_to_action_json):
    data = bytes(u8)
    try:
        raw_actions = json.loads(idx_to_action_json or "{}")
        if not isinstance(raw_actions, dict):
            raw_actions = {}
    except Exception:
        raw_actions = {}

    normalized_actions = {}
    for k, v in raw_actions.items():
        try:
            idx = int(k)
        except Exception:
            continue
        normalized_actions[idx] = str(v).upper()

    plan = {
        "styleMap": {},
        "styleMapSize": 0,
        "hasStylesXml": False,
        "parts": [],
        "idxToAction": normalized_actions,
        "rawActions": raw_actions,
        "unmatchedActions": [],
        "totalHeadings": 0,
    }

    try:
        zf = zipfile.ZipFile(io.BytesIO(data), "r")
    except Exception as exc:
        plan["error"] = f"zip-error:{exc}"
        return json.dumps(plan, ensure_ascii=False)

    with zf as zfin:
        names = set(zfin.namelist())
        plan["hasStylesXml"] = "word/styles.xml" in names
        style_map = _build_heading_style_map(zfin)
        plan["styleMap"] = style_map
        plan["styleMapSize"] = len(style_map)

        doc_parts = [n for n in names if n == "word/document.xml"]
        global_idx = 0
        seen_indices = set()

        for part in doc_parts:
            info = {
                "name": part,
                "headings": [],
                "removalRanges": [],
                "blockCount": 0,
                "errors": [],
            }
            try:
                raw = zfin.read(part)
            except KeyError:
                info["errors"].append("missing-part")
                plan["parts"].append(info)
                continue
            try:
                root = ET.fromstring(raw)
            except ET.ParseError as exc:
                info["errors"].append(f"parse-error:{exc}")
                plan["parts"].append(info)
                continue
            body = root.find(_q("body"))
            if body is None:
                info["errors"].append("no-body")
                plan["parts"].append(info)
                continue

            elems = _collect_body_blocks(body, style_map)
            info["blockCount"] = len(elems)

            heading_positions = []

            for pos, blk in enumerate(elems):
                if blk.get("type") != "p":
                    continue
                lvl = blk.get("level")
                if not isinstance(lvl, int) or lvl <= 0:
                    continue
                idx = global_idx
                global_idx += 1
                trace_lvl, reason = _heading_level_trace(blk.get("element"), style_map)
                if isinstance(trace_lvl, int) and trace_lvl > 0:
                    lvl = trace_lvl
                heading_positions.append((pos, lvl, idx))
                heading_info = {
                    "idx": idx,
                    "level": lvl,
                    "position": pos,
                    "text": _paragraph_plain_text(blk.get("element")),
                    "action": normalized_actions.get(idx),
                    "detectedBy": reason or "",
                }
                info["headings"].append(heading_info)
                seen_indices.add(idx)

            for h_i, (pos, lvl, idx) in enumerate(heading_positions):
                if normalized_actions.get(idx) != "HIDE":
                    continue
                end = len(elems)
                for j in range(h_i + 1, len(heading_positions)):
                    np, nl, _ = heading_positions[j]
                    if nl <= lvl:
                        end = np
                        break
                removal = {
                    "idx": idx,
                    "level": lvl,
                    "startBlock": pos,
                    "endBlock": end,
                    "blockCount": max(0, end - pos),
                }
                for h in info["headings"]:
                    if h.get("idx") == idx:
                        removal["headingText"] = h.get("text")
                        break
                info["removalRanges"].append(removal)

            plan["parts"].append(info)

        plan["totalHeadings"] = global_idx
        unmatched = []
        for idx in sorted(normalized_actions.keys()):
            if idx not in seen_indices:
                unmatched.append(idx)
        plan["unmatchedActions"] = unmatched

    return json.dumps(plan, ensure_ascii=False)

def _paragraph_plain_text(p_el):
    if p_el is None:
        return ""
    parts = []
    for t in p_el.findall(".//w:t", {"w": _W_NS}):
        if t.text:
            parts.append(t.text)
    return "".join(parts)

def inspect_export_removal_plan(u8, idx_to_action_json):
    data = bytes(u8)
    try:
        raw_actions = json.loads(idx_to_action_json or "{}")
        if not isinstance(raw_actions, dict):
            raw_actions = {}
    except Exception:
        raw_actions = {}

    normalized_actions = {}
    for k, v in raw_actions.items():
        try:
            idx = int(k)
        except Exception:
            continue
        normalized_actions[idx] = str(v).upper()

    plan = {
        "styleMap": {},
        "styleMapSize": 0,
        "hasStylesXml": False,
        "parts": [],
        "idxToAction": normalized_actions,
        "rawActions": raw_actions,
        "unmatchedActions": [],
        "totalHeadings": 0,
    }

    try:
        zf = zipfile.ZipFile(io.BytesIO(data), "r")
    except Exception as exc:
        plan["error"] = f"zip-error:{exc}"
        return json.dumps(plan, ensure_ascii=False)

    with zf as zfin:
        names = set(zfin.namelist())
        plan["hasStylesXml"] = "word/styles.xml" in names
        style_map = _build_heading_style_map(zfin)
        plan["styleMap"] = style_map
        plan["styleMapSize"] = len(style_map)

        doc_parts = [n for n in names if n == "word/document.xml"]
        global_idx = 0
        seen_indices = set()

        for part in doc_parts:
            info = {
                "name": part,
                "headings": [],
                "removalRanges": [],
                "blockCount": 0,
                "errors": [],
            }
            try:
                raw = zfin.read(part)
            except KeyError:
                info["errors"].append("missing-part")
                plan["parts"].append(info)
                continue
            try:
                root = ET.fromstring(raw)
            except ET.ParseError as exc:
                info["errors"].append(f"parse-error:{exc}")
                plan["parts"].append(info)
                continue
            body = root.find(_q("body"))
            if body is None:
                info["errors"].append("no-body")
                plan["parts"].append(info)
                continue

            elems = _collect_body_blocks(body, style_map)
            info["blockCount"] = len(elems)

            heading_positions = []

            for pos, blk in enumerate(elems):
                if blk.get("type") != "p":
                    continue
                lvl = blk.get("level")
                if not isinstance(lvl, int) or lvl <= 0:
                    continue
                idx = global_idx
                global_idx += 1
                trace_lvl, reason = _heading_level_trace(blk.get("element"), style_map)
                if isinstance(trace_lvl, int) and trace_lvl > 0:
                    lvl = trace_lvl
                heading_positions.append((pos, lvl, idx))
                heading_info = {
                    "idx": idx,
                    "level": lvl,
                    "position": pos,
                    "text": _paragraph_plain_text(blk.get("element")),
                    "action": normalized_actions.get(idx),
                    "detectedBy": reason or "",
                }
                info["headings"].append(heading_info)
                seen_indices.add(idx)

            for h_i, (pos, lvl, idx) in enumerate(heading_positions):
                if normalized_actions.get(idx) != "HIDE":
                    continue
                end = len(elems)
                for j in range(h_i + 1, len(heading_positions)):
                    np, nl, _ = heading_positions[j]
                    if nl <= lvl:
                        end = np
                        break
                removal = {
                    "idx": idx,
                    "level": lvl,
                    "startBlock": pos,
                    "endBlock": end,
                    "blockCount": max(0, end - pos),
                }
                for h in info["headings"]:
                    if h.get("idx") == idx:
                        removal["headingText"] = h.get("text")
                        break
                info["removalRanges"].append(removal)

            plan["parts"].append(info)

        plan["totalHeadings"] = global_idx
        unmatched = []
        for idx in sorted(normalized_actions.keys()):
            if idx not in seen_indices:
                unmatched.append(idx)
        plan["unmatchedActions"] = unmatched

    return json.dumps(plan, ensure_ascii=False)

def _paragraph_plain_text(p_el):
    if p_el is None:
        return ""
    parts = []
    for t in p_el.findall(".//w:t", {"w": _W_NS}):
        if t.text:
            parts.append(t.text)
    return "".join(parts)

def inspect_export_removal_plan(u8, idx_to_action_json):
    data = bytes(u8)
    try:
        raw_actions = json.loads(idx_to_action_json or "{}")
        if not isinstance(raw_actions, dict):
            raw_actions = {}
    except Exception:
        raw_actions = {}

    normalized_actions = {}
    for k, v in raw_actions.items():
        try:
            idx = int(k)
        except Exception:
            continue
        normalized_actions[idx] = str(v).upper()

    plan = {
        "styleMap": {},
        "styleMapSize": 0,
        "hasStylesXml": False,
        "parts": [],
        "idxToAction": normalized_actions,
        "rawActions": raw_actions,
        "unmatchedActions": [],
        "totalHeadings": 0,
    }

    try:
        zf = zipfile.ZipFile(io.BytesIO(data), "r")
    except Exception as exc:
        plan["error"] = f"zip-error:{exc}"
        return json.dumps(plan, ensure_ascii=False)

    with zf as zfin:
        names = set(zfin.namelist())
        plan["hasStylesXml"] = "word/styles.xml" in names
        style_map = _build_heading_style_map(zfin)
        plan["styleMap"] = style_map
        plan["styleMapSize"] = len(style_map)

        doc_parts = [n for n in names if n == "word/document.xml"]
        global_idx = 0
        seen_indices = set()

        for part in doc_parts:
            info = {
                "name": part,
                "headings": [],
                "removalRanges": [],
                "blockCount": 0,
                "errors": [],
            }
            try:
                raw = zfin.read(part)
            except KeyError:
                info["errors"].append("missing-part")
                plan["parts"].append(info)
                continue
            try:
                root = ET.fromstring(raw)
            except ET.ParseError as exc:
                info["errors"].append(f"parse-error:{exc}")
                plan["parts"].append(info)
                continue
            body = root.find(_q("body"))
            if body is None:
                info["errors"].append("no-body")
                plan["parts"].append(info)
                continue

            elems = _collect_body_blocks(body, style_map)
            info["blockCount"] = len(elems)

            heading_positions = []

            for pos, blk in enumerate(elems):
                if blk.get("type") != "p":
                    continue
                lvl = blk.get("level")
                if not isinstance(lvl, int) or lvl <= 0:
                    continue
                idx = global_idx
                global_idx += 1
                trace_lvl, reason = _heading_level_trace(blk.get("element"), style_map)
                if isinstance(trace_lvl, int) and trace_lvl > 0:
                    lvl = trace_lvl
                heading_positions.append((pos, lvl, idx))
                heading_info = {
                    "idx": idx,
                    "level": lvl,
                    "position": pos,
                    "text": _paragraph_plain_text(blk.get("element")),
                    "action": normalized_actions.get(idx),
                    "detectedBy": reason or "",
                }
                info["headings"].append(heading_info)
                seen_indices.add(idx)

            for h_i, (pos, lvl, idx) in enumerate(heading_positions):
                if normalized_actions.get(idx) != "HIDE":
                    continue
                end = len(elems)
                for j in range(h_i + 1, len(heading_positions)):
                    np, nl, _ = heading_positions[j]
                    if nl <= lvl:
                        end = np
                        break
                removal = {
                    "idx": idx,
                    "level": lvl,
                    "startBlock": pos,
                    "endBlock": end,
                    "blockCount": max(0, end - pos),
                }
                for h in info["headings"]:
                    if h.get("idx") == idx:
                        removal["headingText"] = h.get("text")
                        break
                info["removalRanges"].append(removal)

            plan["parts"].append(info)

        plan["totalHeadings"] = global_idx
        unmatched = []
        for idx in sorted(normalized_actions.keys()):
            if idx not in seen_indices:
                unmatched.append(idx)
        plan["unmatchedActions"] = unmatched

    return json.dumps(plan, ensure_ascii=False)

def _paragraph_plain_text(p_el):
    if p_el is None:
        return ""
    parts = []
    for t in p_el.findall(".//w:t", {"w": _W_NS}):
        if t.text:
            parts.append(t.text)
    return "".join(parts)

def inspect_export_removal_plan(u8, idx_to_action_json):
    data = bytes(u8)
    try:
        raw_actions = json.loads(idx_to_action_json or "{}")
        if not isinstance(raw_actions, dict):
            raw_actions = {}
    except Exception:
        raw_actions = {}

    normalized_actions = {}
    for k, v in raw_actions.items():
        try:
            idx = int(k)
        except Exception:
            continue
        normalized_actions[idx] = str(v).upper()

    plan = {
        "styleMap": {},
        "styleMapSize": 0,
        "hasStylesXml": False,
        "parts": [],
        "idxToAction": normalized_actions,
        "rawActions": raw_actions,
        "unmatchedActions": [],
        "totalHeadings": 0,
    }

    try:
        zf = zipfile.ZipFile(io.BytesIO(data), "r")
    except Exception as exc:
        plan["error"] = f"zip-error:{exc}"
        return json.dumps(plan, ensure_ascii=False)

    with zf as zfin:
        names = set(zfin.namelist())
        plan["hasStylesXml"] = "word/styles.xml" in names
        style_map = _build_heading_style_map(zfin)
        plan["styleMap"] = style_map
        plan["styleMapSize"] = len(style_map)

        doc_parts = [n for n in names if n == "word/document.xml"]
        global_idx = 0
        seen_indices = set()

        for part in doc_parts:
            info = {
                "name": part,
                "headings": [],
                "removalRanges": [],
                "blockCount": 0,
                "errors": [],
            }
            try:
                raw = zfin.read(part)
            except KeyError:
                info["errors"].append("missing-part")
                plan["parts"].append(info)
                continue
            try:
                root = ET.fromstring(raw)
            except ET.ParseError as exc:
                info["errors"].append(f"parse-error:{exc}")
                plan["parts"].append(info)
                continue
            body = root.find(_q("body"))
            if body is None:
                info["errors"].append("no-body")
                plan["parts"].append(info)
                continue

            elems = _collect_body_blocks(body, style_map)
            info["blockCount"] = len(elems)

            heading_positions = []

            for pos, blk in enumerate(elems):
                if blk.get("type") != "p":
                    continue
                lvl = blk.get("level")
                if not isinstance(lvl, int) or lvl <= 0:
                    continue
                idx = global_idx
                global_idx += 1
                trace_lvl, reason = _heading_level_trace(blk.get("element"), style_map)
                if isinstance(trace_lvl, int) and trace_lvl > 0:
                    lvl = trace_lvl
                heading_positions.append((pos, lvl, idx))
                heading_info = {
                    "idx": idx,
                    "level": lvl,
                    "position": pos,
                    "text": _paragraph_plain_text(blk.get("element")),
                    "action": normalized_actions.get(idx),
                    "detectedBy": reason or "",
                }
                info["headings"].append(heading_info)
                seen_indices.add(idx)

            for h_i, (pos, lvl, idx) in enumerate(heading_positions):
                if normalized_actions.get(idx) != "HIDE":
                    continue
                end = len(elems)
                for j in range(h_i + 1, len(heading_positions)):
                    np, nl, _ = heading_positions[j]
                    if nl <= lvl:
                        end = np
                        break
                removal = {
                    "idx": idx,
                    "level": lvl,
                    "startBlock": pos,
                    "endBlock": end,
                    "blockCount": max(0, end - pos),
                }
                for h in info["headings"]:
                    if h.get("idx") == idx:
                        removal["headingText"] = h.get("text")
                        break
                info["removalRanges"].append(removal)

            plan["parts"].append(info)

        plan["totalHeadings"] = global_idx
        unmatched = []
        for idx in sorted(normalized_actions.keys()):
            if idx not in seen_indices:
                unmatched.append(idx)
        plan["unmatchedActions"] = unmatched

    return json.dumps(plan, ensure_ascii=False)

# ---------- removal/backup/cleanup helpers ----------
def _is_empty_para(p):
    if p.findall(".//w:fldSimple", {"w": _W_NS}): return False
    if p.findall(".//w:drawing", {"w": _W_NS}): return False
    if p.findall(".//w:object",  {"w": _W_NS}): return False
    if p.findall(".//w:pict",    {"w": _W_NS}): return False
    ts = p.findall(".//w:t", {"w": _W_NS})
    return all(((t.text or "").strip() == "") for t in ts)

def _has_page_break_run(p):
    for br in p.findall(".//w:br", {"w": _W_NS}):
        t = br.get(_q("type"))
        if (t or "").lower() == "page":
            return True
    return False

def _has_page_break_before(p):
    pPr = p.find(_q("pPr"))
    if pPr is None: return False
    return pPr.find(_q("pageBreakBefore")) is not None

def _compact_whitespace(root):
    body = root.find(_q("body")) or root
    # remove empty paragraphs unless they carry a page break
    for node in list(body):
        if node.tag == _q("p"):
            keep_for_page = _has_page_break_run(node) or _has_page_break_before(node)
            if (not keep_for_page) and _is_empty_para(node):
                try: body.remove(node)
                except: pass
    # collapse duplicate page-break-only paras
    def _is_pure_pb(p):
        if p.tag != _q("p"): return False
        if not _has_page_break_run(p): return False
        ts = p.findall(".//w:t", {"w": _W_NS})
        return all(((t.text or "").strip() == "") for t in ts)
    prev_pb = False
    for node in list(body):
        if _is_pure_pb(node):
            if prev_pb:
                try: body.remove(node)
                except: pass
            else:
                prev_pb = True
        else:
            prev_pb = False

def _prune_empty_sdts(root):
    # best-effort: remove SDTs whose content has only empty paragraphs (no tables)
    for sdt in list(root.findall(".//w:sdt", {"w": _W_NS})):
        content = sdt.find(_q("sdtContent"))
        if content is None:
            continue
        if content.find(".//w:tbl", {"w": _W_NS}) is not None:
            continue
        keep = False
        for p in content.findall(".//w:p", {"w": _W_NS}):
            if not _is_empty_para(p):
                keep = True
                break
        if not keep:
            # remove sdt by scanning parent
            removed = False
            for cand in root.iter():
                for ch in list(cand):
                    if ch is sdt:
                        try: cand.remove(ch); removed = True
                        except: pass
                        break
                if removed: break

def _prune_dead_tables(root):
    for tbl in list(root.findall(".//w:tbl", {"w": _W_NS})):
        trs = tbl.findall(".//w:tr", {"w": _W_NS})
        has_cell = False
        for tr in trs:
            if tr.find(".//w:tc", {"w": _W_NS}) is not None:
                has_cell = True; break
        if not has_cell:
            # remove this <w:tbl>
            removed = False
            for cand in root.iter():
                for ch in list(cand):
                    if ch is tbl:
                        try: cand.remove(ch); removed = True
                        except: pass
                        break
                if removed: break

def _ensure_backup_embedded(zfin, zfout, names, backup_path="customXml/originalDocument.xml", override_bytes=None):
    if backup_path in names:
        # Already present â†’ keep existing backup to preserve the untouched original
        return
    if override_bytes is not None:
        try:
            zfout.writestr(backup_path, override_bytes)
        except Exception:
            pass
        return
    try:
        orig = zfin.read("word/document.xml")
        zfout.writestr(backup_path, orig)
    except KeyError:
        pass

def restore_document_from_backup(u8, backup_path="customXml/originalDocument.xml"):
    data = bytes(u8)
    with zipfile.ZipFile(io.BytesIO(data), "r") as zfin:
        try:
            original = zfin.read(backup_path)
        except KeyError:
            return data
        outbuf = io.BytesIO()
        with zipfile.ZipFile(outbuf, "w", compression=zipfile.ZIP_DEFLATED) as zfout:
            for name in zfin.namelist():
                if name == "word/document.xml":
                    continue
                zfout.writestr(name, zfin.read(name))
            zfout.writestr("word/document.xml", original)
    return outbuf.getvalue()

def _ensure_update_fields(zfin, zfout):
    try:
        raw = zfin.read("word/settings.xml")
        try:
            root = ET.fromstring(raw)
        except ET.ParseError:
            root = ET.Element(_q("settings"))
    except KeyError:
        root = ET.Element(_q("settings"))

    upd = root.find(_q("updateFields"))
    if upd is None:
        upd = ET.SubElement(root, _q("updateFields"))
    upd.set(_q("val"), "true")

    zfout.writestr("word/settings.xml", ET.tostring(root, encoding="utf-8", xml_declaration=True))

def _extract_part_from_bytes(data_like, part_name):
    if data_like is None:
        return None
    try:
        data = bytes(data_like)
    except Exception:
        return None
    try:
        with zipfile.ZipFile(io.BytesIO(data), "r") as zf:
            return zf.read(part_name)
    except Exception:
        return None

# ----- TOC minimal rebuild -----
def _next_in_doc_order(node, root):
    if node is None: return None
    found = False
    for el in root.iter():
        if found: return el
        if el is node: found = True
    return None

def _find_toc_ranges(root):
    ranges = []
    body = root.find(_q("body")) or root
    fldChars = root.findall(".//w:fldChar", {"w": _W_NS})
    for begin in fldChars:
        if begin.get(_q("val")) != "begin":
            continue
        cur = begin
        instr = ""
        separate = None
        end = None
        while True:
            cur = _next_in_doc_order(cur, body)
            if cur is None: break
            if cur.tag == _q("instrText"): instr += (cur.text or "")
            if cur.tag == _q("fldChar"):
                v = cur.get(_q("val"))
                if v == "separate": separate = cur
                if v == "end":
                    end = cur
                    break
        u = (instr or "").strip().upper()
        if u.startswith("TOC"):
            if separate is not None and end is not None:
                ranges.append((begin, separate, end, instr))
    return ranges

def _rebuild_toc(root): 
    # Replace existing complex range with a minimal fldSimple paragraph
    for (begin, separate, end, instr) in _find_toc_ranges(root):
        switches = (instr.strip() if instr else r'TOC \\o "1-3" \\h \\z \\u')
        # locate host paragraph of 'begin'
        host_p = None
        for par in root.findall(".//w:p", {"w": _W_NS}):
            for el in par.iter():
                if el is begin:
                    host_p = par; break
            if host_p is not None: break
        if host_p is None: continue
        # parent of host_p
        parent = None
        for cand in root.iter():
            for ch in list(cand):
                if ch is host_p:
                    parent = cand; break
            if parent is not None: break
        if parent is None: continue

        # new paragraph with simple TOC field
        p = ET.Element(_q("p"))
        fld = ET.SubElement(p, _q("fldSimple"), {_q("instr"): switches})
        r = ET.SubElement(fld, _q("r")); ET.SubElement(r, _q("t")).text = ""

        idx = list(parent).index(host_p)
        parent.insert(idx, p)

        # remove host_p and following siblings up to node that contains 'end'
        # Simplest: rebuild parent's children excluding nodes that belong to the TOC range
        new_children = []
        skipping = False
        end_reached = False
        for ch in list(parent):
            if not skipping and ch is host_p:
                skipping = True
                continue
            if skipping:
                hit_end = False
                for el in ch.iter():
                    if el is end:
                        hit_end = True; break
                if hit_end:
                    skipping = False
                    end_reached = True
                    continue
                else:
                    continue
            new_children.append(ch)
        # replace
        for ch in list(parent): parent.remove(ch)
        for ch in new_children: parent.append(ch)

# ---------- CORE: remove ranges & embed backup ----------
def apply_removal_with_backup(u8, idx_to_action_json, backup_path="customXml/originalDocument.xml", original_bytes=None):
    """
    idx_to_action_json: {"12":"HIDE","13":"SHOW", ...}
      - For headings where action == "HIDE": remove [heading .. next heading with <= level)
      - Embed original as customXml/originalDocument.xml (if not already present)
      - Cleanup empty SDTs, dead tables, whitespace
      - Rebuild TOC (minimal fldSimple form)
    """
    try:
        idx_to_action = {int(k): v for (k, v) in json.loads(idx_to_action_json).items()}
    except Exception:
        idx_to_action = {}

    data = bytes(u8)
    override_backup = _extract_part_from_bytes(original_bytes, "word/document.xml")
    outbuf = io.BytesIO()

    with zipfile.ZipFile(io.BytesIO(data), "r") as zfin, \
         zipfile.ZipFile(outbuf, "w", compression=zipfile.ZIP_DEFLATED) as zfout:

        names = zfin.namelist()
        # Copy everything first
        for n in names:
            zfout.writestr(n, zfin.read(n))

        # Ensure embedded backup exists (using untouched original if provided)
        _ensure_backup_embedded(zfin, zfout, names, backup_path=backup_path, override_bytes=override_backup)

        # Process primary document (you can extend to headers/footers if needed)
        doc_parts = [n for n in names if n == "word/document.xml"]
        style_map = _build_heading_style_map(zfin)

        global_idx = 0
        for part in doc_parts:
            try:
                root = ET.fromstring(zfin.read(part))
            except ET.ParseError:
                continue

            body = root.find(_q("body"))
            if body is None:
                zfout.writestr(part, ET.tostring(root, encoding="utf-8", xml_declaration=True))
                continue

            elems = _collect_body_blocks(body, style_map)

            heading_positions = []
            for i, blk in enumerate(elems):
                if blk.get("type") != "p":
                    continue
                lvl = blk.get("level")
                if not isinstance(lvl, int) or lvl <= 0:
                    continue
                idx = global_idx
                global_idx += 1
                heading_positions.append((i, lvl, idx))

            to_remove_top_nodes = set()
            for h_i, (pos, lvl, idx) in enumerate(heading_positions):
                if idx_to_action.get(idx) != "HIDE":
                    continue
                # compute end boundary
                if h_i + 1 < len(heading_positions):
                    end = len(elems)
                    for j in range(h_i + 1, len(heading_positions)):
                        np, nl, _ = heading_positions[j]
                        if nl <= lvl:
                            end = np
                            break
                else:
                    end = len(elems)
                # gather distinct top nodes to remove (no duplicates)
                seen = set()
                for j in range(pos, end):
                    top = elems[j].get("top")
                    if top is None: continue
                    k = id(top)
                    if k in seen: continue
                    seen.add(k)
                    to_remove_top_nodes.add(top)

            # Remove nodes by scanning parents (xml.etree has no getparent)
            if to_remove_top_nodes:
                for cand in root.iter():
                    for ch in list(cand):
                        if ch in to_remove_top_nodes:
                            try: cand.remove(ch)
                            except: pass

            # Cleanup & TOC rebuild
            _prune_empty_sdts(root)
            _prune_dead_tables(root)
            _compact_whitespace(root)
            _rebuild_toc(root)

            zfout.writestr(part, ET.tostring(root, encoding="utf-8", xml_declaration=True))

        # Align settings with Word expectations (updateFields must be true)
        _ensure_update_fields(zfin, zfout)

    return outbuf.getvalue()
`);
        tr.end('pyodide ready');
        return py;
      } catch (e) { tr.error('bootstrap failed', e); tr.end(); throw e; }
    })();

    async function readDocVarSettings(arrayBufferOrBytes, name) {
      const tr = TRACE('readDocVarSettings', { name });
      try {
        const py = await pyodideReady;
        const u8in = arrayBufferOrBytes instanceof Uint8Array ? arrayBufferOrBytes : new Uint8Array(arrayBufferOrBytes);
        const fn = py.globals.get('read_docvar_settings');
        const pyBytes = py.toPy(u8in);
        let pyOut;
        try { pyOut = fn(pyBytes, name); }
        finally { try{fn.destroy();}catch{} try{pyBytes.destroy();}catch{} }
        let txt = null;
        if (pyOut?.toJs) txt = pyOut.toJs({ create_proxies:false });
        else txt = pyOut ?? null;
        try { pyOut.destroy?.(); } catch {}
        tr.end({ found: !!txt, len: txt?.length });
        return txt;
      } catch (e) { tr.error('failed', e); tr.end(); return null; }
    }

    async function readDocVarCustom(arrayBufferOrBytes, name) {
      const tr = TRACE('readDocVarCustom', { name });
      try {
        const py = await pyodideReady;
        const u8in = arrayBufferOrBytes instanceof Uint8Array ? arrayBufferOrBytes : new Uint8Array(arrayBufferOrBytes);
        const fn = py.globals.get('read_docvar_custom');
        const pyBytes = py.toPy(u8in);
        let pyOut;
        try { pyOut = fn(pyBytes, name); }
        finally { try{fn.destroy();}catch{} try{pyBytes.destroy();}catch{} }
        let txt = null;
        if (pyOut?.toJs) txt = pyOut.toJs({ create_proxies:false });
        else txt = pyOut ?? null;
        try { pyOut.destroy?.(); } catch {}
        tr.end({ found: !!txt, len: txt?.length });
        return txt;
      } catch (e) { tr.error('failed', e); tr.end(); return null; }
    }

    async function writeDocVarSettings(arrayBufferOrBytes, name, value) {
      const tr = TRACE('writeDocVarSettings', { name, valueLen: (value||'').length });
      try {
        const py = await pyodideReady;
        const u8in = arrayBufferOrBytes instanceof Uint8Array ? arrayBufferOrBytes : new Uint8Array(arrayBufferOrBytes);
        const fn = py.globals.get('write_docvar_settings');
        const pyBytes = py.toPy(u8in);
        let pyOut;
        try { pyOut = fn(pyBytes, name, String(value ?? "")); }
        finally { try{fn.destroy();}catch{} try{pyBytes.destroy();}catch{} }
        let u8;
        if (pyOut?.toJs) u8 = pyOut.toJs({ create_proxies:false });
        else if (pyOut?.getBuffer) u8 = new Uint8Array(pyOut.getBuffer());
        else u8 = new Uint8Array([]);
        try { pyOut.destroy?.(); } catch {}
        tr.end({ outLen: u8?.byteLength });
        return u8;
      } catch (e) { tr.error('failed', e); tr.end(); throw e; }
    }

    async function writeSDTs(arrayBufferOrBytes, tagToTextObj) {
      const tr = TRACE('writeSDTs', { tagCount: Object.keys(tagToTextObj||{}).length });
      try {
        const py = await pyodideReady;
        const u8in = arrayBufferOrBytes instanceof Uint8Array ? arrayBufferOrBytes : new Uint8Array(arrayBufferOrBytes);
        const fn = py.globals.get('write_sdts_by_tag');
        const pyBytes   = py.toPy(u8in);
        const pyMap     = py.toPy(JSON.stringify(tagToTextObj || {}));
        let pyOut;
        try { pyOut = fn(pyBytes, pyMap); }
        finally { try{fn.destroy();}catch{} try{pyBytes.destroy();}catch{} try{pyMap.destroy();}catch{} }
        let u8;
        if (pyOut?.toJs) u8 = pyOut.toJs({ create_proxies:false });
        else if (pyOut?.getBuffer) u8 = new Uint8Array(pyOut.getBuffer());
        else u8 = new Uint8Array([]);
        try { pyOut.destroy?.(); } catch {}
        tr.end({ outLen: u8?.byteLength });
        return u8;
      } catch (e) { tr.error('failed', e); tr.end(); throw e; }
    }

    // ---------- Helpers: sanitize ----------
    function sanitizeValues(schema, vals) {
      const out = {};
      const fields = Array.isArray(schema?.fields) ? schema.fields : [];

      for (const f of fields) {
        const id = f.id;
        let v = vals?.[id];

        if (f.type === 'datediff') {
          const d = vals?.[id];
          if (d && typeof d === 'object') {
            const outObj = {
              days: Number(d.days ?? 0),
              months: Number(d.months ?? 0),
              years: Number(d.years ?? 0),
              formatted: String(d.formatted ?? '')
            };
            if (outObj.formatted) out[id] = outObj;
          } else if (Number.isFinite(Number(d))) {
            const n = Number(d);
            out[id] = { days: n, months: 0, years: 0, formatted: `${n}-0-0 (${n})` };
          }
          continue;
        }

        if (f.type === 'address') {
          const vv = vals?.[id];
          if (typeof vv === 'string') {
            const s = vv.trim();
            if (s || f.required) out[id] = s ? { formatted: s } : { formatted: '' };
          } else if (vv && typeof vv === 'object') {
            const o = {
              formatted: vv.formatted || '',
              street: vv.street || '',
              houseNumber: vv.houseNumber || '',
              postcode: vv.postcode || '',
              city: vv.city || '',
              country: vv.country || '',
              lat: (vv.lat ?? null),
              lon: (vv.lon ?? null)
            };
            if (o.formatted || f.required) out[id] = o;
          }
          continue;
        }

        if (f.type === 'multichoice') {
          const arr = Array.isArray(v) ? v.map(x => String(x || '')) : [];
          const unique = [];
          const seen = new Set();
          for (const item of arr) {
            if (seen.has(item)) continue;
            seen.add(item);
            unique.push(item);
          }
          if (unique.length) out[id] = unique;
          else if (f.required) out[id] = [];
          continue;
        }

        if (f.type === 'select') {
          let s = Array.isArray(v) ? String(v[0] ?? '') : String(v ?? '');
          if (Array.isArray(f.options) && f.options.length) {
            const allowed = new Set(f.options.map(String));
            if (!allowed.has(s)) s = '';
          }
          if (s === '') { if (f.required) out[id] = s; }
          else out[id] = s;
          continue;
        }

        if (f.type === 'number') {
          if (v === '' || v == null) continue;
          const num = (typeof v === 'number') ? v : Number(String(v).replace(',', '.'));
          if (Number.isFinite(num)) out[id] = num;
          continue;
        }

        if (f.type === 'date') { out[id] = String(v ?? ''); continue; }

        if (f.type === 'table') {
          const cols = Array.isArray(f.columns) ? f.columns : [];
          const colIds = cols.map(c => c.id);
          const arr = Array.isArray(v) ? v : [];
          const cleaned = arr.map(row => {
            const o = {};
            for (const cid of colIds) {
              let cell = row?.[cid];
              if (cell == null) cell = '';
              o[cid] = (typeof cell === 'string') ? cell : String(cell);
            }
            return o;
          }).filter(r => Object.values(r).some(val => String(val).trim() !== ''));
          const min = Math.max(0, parseInt(f.minRows || 0, 10));
          while (cleaned.length < min) {
            const empty = {}; colIds.forEach(cid => empty[cid] = '', cleaned.push(empty));
          }
          if (cleaned.length) out[id] = cleaned;
          else if (f.required) out[id] = [];
          continue;
        }

        const s = String(v ?? '');
        if (s || f.required) out[id] = s;
      }

      return out;
    }

    function sanitizeTagMap(tagMap, validIds) {
      const out = {};
      for (const [tag, fid] of Object.entries(tagMap || {})) {
        if (validIds.has(fid)) out[tag] = fid;
      }
      return out;
    }

    const serializeVisibilityMapForPython = (map) => {
      const remapped = {};
      for (const [key, value] of Object.entries(map || {})) {
        const num = Number(key);
        if (Number.isFinite(num)) remapped[num] = value;
        else remapped[key] = value;
      }
      return JSON.stringify(remapped);
    };

    async function inspectRemovalPlan(bytesU8, visibilityMap) {
      await ensurePy();
      const fn = py.globals.get('inspect_export_removal_plan');
      const buf = bytesU8 instanceof Uint8Array ? bytesU8 : new Uint8Array(bytesU8 || []);
      const pyBytes = py.toPy(buf);
      const pyMap = py.toPy(serializeVisibilityMapForPython(visibilityMap));
      let pyOut;
      try {
        pyOut = fn(pyBytes, pyMap);
      } finally {
        try { fn.destroy(); } catch {}
        try { pyBytes.destroy(); } catch {}
        try { pyMap.destroy(); } catch {}
      }
      let out = null;
      if (pyOut?.toJs) out = pyOut.toJs({ create_proxies:false });
      else out = pyOut ?? null;
      try { pyOut?.destroy?.(); } catch {}
      if (typeof out === 'string') {
        try { return JSON.parse(out); }
        catch { return { error: 'parse-error', raw: out }; }
      }
      return out;
    }

    async function applyRemovalWithBackup(bytesU8, visibilityMap, originalBytes) {
      await ensurePy();
      const fn = py.globals.get('apply_removal_with_backup');
      const buf = bytesU8 instanceof Uint8Array ? bytesU8 : new Uint8Array(bytesU8);
      const pyBytes = py.toPy(buf);
      const pyMap   = py.toPy(serializeVisibilityMapForPython(visibilityMap));
      const pyPath  = py.toPy('customXml/originalDocument.xml');
      const origBuf = (originalBytes instanceof Uint8Array)
        ? originalBytes
        : (originalBytes ? new Uint8Array(originalBytes) : null);
      let pyOut;
      let pyOrig = null;
      try {
        if (origBuf) {
          pyOrig = py.toPy(origBuf);
          pyOut = fn(pyBytes, pyMap, pyPath, pyOrig);
        } else {
          pyOut = fn(pyBytes, pyMap, pyPath);
        }
      }
      finally {
        try{fn.destroy();}catch{}
        try{pyBytes.destroy();}catch{}
        try{pyMap.destroy();}catch{}
        try{pyPath.destroy();}catch{}
        try{pyOrig?.destroy();}catch{}
      }
      let u8;
      if (pyOut?.toJs) u8 = pyOut.toJs({ create_proxies:false });
      else if (pyOut?.getBuffer) u8 = new Uint8Array(pyOut.getBuffer());
      else u8 = new Uint8Array([]);
      try { pyOut?.destroy?.(); } catch {}
      return u8;
    }

    async function restoreDocxFromBackup(bytesU8, backupPath = 'customXml/originalDocument.xml') {
      await ensurePy();
      const fn = py.globals.get('restore_document_from_backup');
      const buf = bytesU8 instanceof Uint8Array ? bytesU8 : new Uint8Array(bytesU8 || []);
      const pyBytes = py.toPy(buf);
      const pyPath = py.toPy(String(backupPath || 'customXml/originalDocument.xml'));
      let pyOut;
      try {
        pyOut = fn(pyBytes, pyPath);
      } finally {
        try { fn.destroy(); } catch {}
        try { pyBytes.destroy(); } catch {}
        try { pyPath.destroy(); } catch {}
      }
      let u8;
      if (pyOut?.toJs) u8 = pyOut.toJs({ create_proxies:false });
      else if (pyOut?.getBuffer) u8 = new Uint8Array(pyOut.getBuffer());
      else u8 = new Uint8Array(buf);
      try { pyOut?.destroy?.(); } catch {}
      return u8;
    }

    // =========================
    // (REPLACE) renderFromCurrentBytes(prefix = '')
    // =========================
    async function renderFromCurrentBytes(prefix = '') {
      const tr = TRACE('renderFromCurrentBytes', { prefix });
      try {
        setStatus((prefix || '') + 'Parsingâ€¦');

        // 1) SDTs
        const parsed = await parseSDTs_JS(gArrayBuffer);
        gSDTs = parsed.sdts || [];
        renderSDTsView(parsed);

        // 2) Headings (best-effort)
        let headingsParsed = { flat: [], tree: [], count: 0 };
        try {
          headingsParsed = await parseHeadings_JS(gArrayBuffer);
          renderHeadingsTreeView(headingsParsed.tree);
          adoptHeadingBaseline(headingsParsed);
        } catch {
          if (headersTreeEl) headersTreeEl.innerHTML = '<div class="empty">No headings.</div>';
          adoptHeadingBaseline({ flat: [], tree: [] });
        }

        // 3) Payload from DOCX (settings/custom)
        let payloadRaw = await readDocVarSettings(gArrayBuffer, PAYLOAD_KEY);
        if (payloadRaw == null) payloadRaw = await readDocVarCustom(gArrayBuffer, PAYLOAD_KEY);
        let payload = null; try { payload = payloadRaw ? JSON.parse(payloadRaw) : null; } catch { payload = null; }

        const wsState = await window.formSuitePersist.loadState(gDocId);

        // Choose schema: newer wins (workspace vs payload)
        const asTs = (x)=> { const t = Date.parse(x || ''); return Number.isFinite(t) ? t : 0; };
        const pHasSchema = Array.isArray(payload?.fields) && payload.fields.length > 0;
        const pUpdatedTs = asTs(payload?.updatedAt);
        const wsSchemaTs = asTs(wsState?.schemaUpdatedAt);

        const chosenSchema =
          (wsState?.schema && (wsSchemaTs >= pUpdatedTs || !pHasSchema)) ? wsState.schema
          : pHasSchema ? { title: payload.title || 'Form', fields: payload.fields }
          : (loadSchemaFromLocalStorage() || { title: 'Form', fields: [] });

        // Merge values/tagMap (workspace overrides payload)
        const mergedValues = Object.assign({}, payload?.values || {}, wsState?.values || {});
        const mergedTagMap = Object.assign({}, payload?.tagMap || {}, wsState?.tagMap || {});

        // ---------- RULES: prefer workspace arrays if they exist; else fall back to payload ----------
        const { rules: mergedRulesRaw, fieldRules: mergedFieldRaw, source: ruleSourceMeta } =
          resolveRulesForState(wsState || {}, payload || {});

        // ðŸ”Ž DEBUG pre-normalization
        console.log('[Rules][pre-normalize]', {
          src: { rules: ruleSourceMeta.rules, fieldRules: ruleSourceMeta.fieldRules },
          counts: { rules: (mergedRulesRaw||[]).length, fieldRules: (mergedFieldRaw||[]).length },
          contributing: ruleSourceMeta
        });

        // âœ… Normalize EVERYTHING against the **chosen** schema (NOT gSchema yet!)
        const rules      = normalizeHeadingsRulesForSchema(chosenSchema, mergedRulesRaw, headingsParsed);
        const fieldRules = normalizeFieldRulesForSchema(chosenSchema, mergedFieldRaw);

        // ðŸ”Ž DEBUG post-normalization
        console.log('[Rules][post-normalize]', {
          rulesCount: rules.length,
          fieldRulesCount: fieldRules.length,
          sampleRule: rules[0],
          sampleFieldRule: fieldRules[0]
        });

        const { values: prunedValues, tagMap: prunedTagMap } =
          normalizeForSchema(chosenSchema, mergedValues, mergedTagMap);

        // Adopt & persist mirrors so Save/Export see the same view
        gSchema = chosenSchema;
        gValues = prunedValues;

        if (gDocId) {
          const canonical = {
            title: gSchema.title,
            fields: gSchema.fields,
            values: gValues,
            tagMap: prunedTagMap,
            rules,
            fieldRules,
            headingsFlat: headingsParsed.flat,
            headingsTree: headingsParsed.tree,
            updatedAt: new Date().toISOString()
          };
          await window.formSuitePersist.saveState(gDocId, {
            schema: gSchema,
            values: gValues,
            tagMap: prunedTagMap,
            rules, fieldRules,
            headingsFlat: headingsParsed.flat,
            headings: headingsParsed.flat,
            headingsTree: headingsParsed.tree,
            headingsUpdatedAt: new Date().toISOString(),
            payload: { CRONOS_PAYLOAD: canonical },
            CRONOS_PAYLOAD: canonical,
            cronos_payload: canonical,
            schemaUpdatedAt: new Date().toISOString()
          });
        }

        buildForm(document.getElementById('formMount'), gSchema, gValues);
        await updatePreview(gValues);
        setStatus('Ready.');
      } catch (e) {
        tr.error('failed', e);
        setStatus('Error while parsing. See console.');
      } finally {
        tr.end();
      }
    }


    function renderSDTsView(parsed) {
      const tr = TRACE('renderSDTsView', { total: parsed?.total, rows: parsed?.sdts?.length });
      try {
        tableBody.innerHTML = '';
        const sdts = parsed?.sdts || [];
        if (!sdts.length) {
          const trEl = document.createElement('tr');
          const td = document.createElement('td');
          td.colSpan = 5;
          td.textContent = 'No SDTs found in this document.';
          trEl.appendChild(td);
          tableBody.appendChild(trEl);
        } else {
          sdts.forEach((row, i) => {
            const trEl = document.createElement('tr');
            const tdIdx = document.createElement('td'); tdIdx.textContent = String(i + 1); trEl.appendChild(tdIdx);
            const tdPart = document.createElement('td'); tdPart.textContent = row.part || ''; trEl.appendChild(tdPart);
            const tdTag = document.createElement('td'); tdTag.textContent = row.tag || ''; trEl.appendChild(tdTag);
            const tdAlias = document.createElement('td'); tdAlias.textContent = row.alias || ''; trEl.appendChild(tdAlias);
            const tdText = document.createElement('td'); tdText.textContent = row.text || ''; trEl.appendChild(tdText);
            tableBody.appendChild(trEl);
          });
        }
      } finally { tr.end(); }
    }

    // =========================
    // BOOT (auto-restore)
    // =========================
    (async function boot() {
      const tr = TRACE('boot');
      try {
        let meta = readActiveMeta();
        tr.step('readActiveMeta', meta);
        if (!meta?.docId) { meta = window.formSuitePersist?.getCurrentDocMeta?.(); tr.step('getCurrentDocMeta', meta); }
        if (!meta?.docId) { tr.end('no meta; idle'); return; }

        clearUiForNewDoc('Restoring documentâ€¦');
        installRulesUpdatedListener();
        let bytes = await window.formSuitePersist.getBytes?.(meta.docId)
                || await window.formSuitePersist.getCurrentDocBytes?.();
        tr.step('persistence bytes', { len: bytes?.byteLength || bytes?.length });

        if (!bytes && supportsFS) {
          try {
            const h = await window.formSuitePersist.getHandle?.(meta.docId);
            tr.step('getHandle (2nd chance)', { has: !!h });
            if (h?.getFile) {
              try { await window.formSuitePersist.ensurePermission?.(h, 'read'); } catch {}
              const f = await h.getFile();
              bytes = new Uint8Array(await f.arrayBuffer());
              gFileHandle = h;
              if (!gFileName) {
                const { base, ext } = splitNameAndExt(f.name || meta.name || 'document.docx');
                gFileName = base || 'document';
                gFileExt  = ext || 'docx';
              }
              tr.step('2nd chance handle.getFile ok', { size: bytes.byteLength });
            }
          } catch (e) {
            tr.warn('2nd chance via handle failed', e);
          }
        }
        if (!bytes && supportsFS) {
          try {
            const h = await window.formSuitePersist.getHandle?.(meta.docId);
            tr.step('getHandle', { has: !!h });
            if (h) {
              try { await window.formSuitePersist.ensurePermission?.(h, 'read'); } catch (e) { tr.warn('ensurePermission failed', e); }
              const f = await h.getFile();
              bytes = new Uint8Array(await f.arrayBuffer());
              gFileHandle = h;
              const { base, ext } = splitNameAndExt(f.name || meta.name || 'document.docx');
              gFileName = base || 'document';
              gFileExt  = ext || 'docx';
              tr.step('handle.getFile ok', { name: `${gFileName}.${gFileExt}`, len: bytes.byteLength });
            }
          } catch (e) { tr.warn('handle path failed', e); }
        }

        if (!bytes) { await hardResetDocContext('no bytes / no permission'); tr.end('no bytes'); return; }

        gArrayBuffer = bytes.buffer ?? bytes;

        if (!gFileName) {
          const { base, ext } = splitNameAndExt(meta.name || 'document.docx');
          gFileName = base || 'document';
          gFileExt  = ext || 'docx';
        }
        gDocId = meta.docId;

        tr.step('restored', { docId: gDocId, name: `${gFileName}.${gFileExt}`, len: gArrayBuffer?.byteLength, sha: await sha256Hex(gArrayBuffer) });

        await renderFromCurrentBytes();
        await updateWriteAccessBanner();

        btnSave.disabled = false; btnExport.disabled = false;
        if (btnSaveFromPreview) btnSaveFromPreview.disabled = false;
      } catch (e) { tr.error('boot failed', e); }
      finally { tr.end(); }
    })();

    // =========================
    // PERSIST WRAPPER
    // =========================
    async function persistCurrentDoc(bytesU8, handle, nameNoExt, ext = 'docx') {
      const tr = TRACE('persistCurrentDoc', { hasBytes: !!bytesU8, handle: !!handle, nameNoExt, ext });
      try {
        if (!bytesU8) throw new Error('persistCurrentDoc requires bytes');
        const safeExt = (ext || 'docx').toLowerCase();
        const name    = `${(nameNoExt || 'document').replace(/\.(docx|docm|dotx|dotm)$/i,'')}.${safeExt}`;

        // Always content-address via persistence.js
        if (window.formSuitePersist?.setCurrentDoc) {
          const meta = await window.formSuitePersist.setCurrentDoc({ bytes: bytesU8, handle, name });
          tr.end(meta); return meta;
        }
        if (window.formSuitePersist?.setCurrentDocFromBytes) {
          const meta = await window.formSuitePersist.setCurrentDocFromBytes(bytesU8, { name, handle });
          tr.end(meta); return meta;
        }

        // Last-ditch fallback (shouldnâ€™t normally hit)
        const meta = { docId: 'inline-' + Date.now(), name };
        tr.end(meta); return meta;
      } catch (e) { tr.error('failed', e); tr.end(); throw e; }
    }


    // ---------- Rules â†’ Visibility map (SHOW supersedes HIDE) ----------
    function loadRulesForDoc(state) {
      return (
        state?.rules ||
        state?.payload?.rules ||
        state?.CRONOS_RULES ||
        state?.cronos_rules ||
        []
      );
    }

    function ruleMatchesValue(op, expected, actual) {
      const a = actual;
      if (op === 'equals')    return String(a) === String(expected);
      if (op === 'notEquals') return String(a) !== String(expected);
      if (op === 'anyOf') {
        const arr = Array.isArray(expected) ? expected.map(String) : [String(expected)];
        if (Array.isArray(a)) return a.map(String).some(v => arr.includes(v));
        return arr.includes(String(a));
      }
      if (op === 'allOf') {
        const arr = Array.isArray(expected) ? expected.map(String) : [String(expected)];
        if (!Array.isArray(a)) return false;
        const aset = new Set(a.map(String));
        return arr.every(v => aset.has(v));
      }
      if (op === 'contains')  return String(a ?? '').toLowerCase().includes(String(expected ?? '').toLowerCase());
      return false;
    }

    function evaluateRulesToVisibility(schema, values, rules, headingResolver) {
      const out = Object.create(null);
      if (!Array.isArray(rules) || !rules.length) return out;

      const cleanVals = sanitizeValues(schema, values || {});
      const getVal = (fid) => cleanVals[fid];

      const toSlug = (s) => String(s||'')
        .normalize('NFKD')
        .replace(/[\u0300-\u036f]/g, '')
        .replace(/[^a-zA-Z0-9]+/g, '_')
        .replace(/^_+|_+$/g, '')
        .toLowerCase();

      for (const r of rules) {
        if (!r) continue;

        const action = (String(r.action || '').toUpperCase() === 'SHOW') ? 'SHOW'
                    : (String(r.action || '').toUpperCase() === 'HIDE') ? 'HIDE'
                    : null;
        if (!action) continue;

        const fieldId = r.fieldId || r.field || r.whenField;
        const op      = r.op || r.operator || 'equals';
        const exp     = r.values ?? r.value ?? r.expected;
        const targets = Array.isArray(r.targets) ? r.targets : [];

        // --- match condition ---
        let match = false;

        // option-sourced boolean (e.g., "services__opt__cleaning")
        if (typeof fieldId === 'string' && fieldId.includes('__opt__')) {
          const [baseId, slug] = fieldId.split('__opt__');
          const actualArr = Array.isArray(getVal(baseId)) ? getVal(baseId).map(String) : [];
          const selected = actualArr.some(v => toSlug(v) === String(slug||'').replace(/^_+/,'').toLowerCase());
          const expect = Array.isArray(exp) ? exp[0] : exp;
          const expectBool = (String(expect) === 'true');
          if (op === 'equals') match = (selected === expectBool);
        } else {
          // normal field comparison
          const fld = (schema?.fields||[]).find(f => String(f.id) === String(fieldId));
          const t = String(fld?.type||'').toLowerCase();
          const actual = getVal(fieldId);

          if (t === 'date') {
            const expStr = Array.isArray(exp) ? String(exp[0]||'') : String(exp||'');
            const toDay = (s) => { if (!s) return NaN; const d = new Date(s); return isNaN(d) ? NaN : Date.UTC(d.getFullYear(), d.getMonth(), d.getDate()); };
            const a = toDay(actual);
            const b = toDay(expStr);
            if (Number.isNaN(a) || Number.isNaN(b)) match = false;
            else if (op === 'before') match = a < b;
            else if (op === 'after')  match = a > b;
            else if (op === 'equals') match = a === b;
          } else if (t === 'text' || t === 'number' || t === 'select') {
            const expVal = Array.isArray(exp) ? exp[0] : exp;
            if (op === 'equals')    match = String(actual) === String(expVal);
            else if (op === 'notEquals') match = String(actual) !== String(expVal);
            else if (t === 'text' && op === 'contains') match = String(actual ?? '').toLowerCase().includes(String(expVal ?? '').toLowerCase());
          } else if (t === 'multichoice') {
            match = ruleMatchesValue(op, exp, actual);
          } else {
            match = ruleMatchesValue(op, exp, actual);
          }
        }

        if (!match) continue;

        // --- apply effect to heading indices ---
        for (const t of targets) {
          const idx = parseTargetIdx(t, headingResolver);
          if (!Number.isFinite(idx)) continue;
          const prev = out[idx];
          if (action === 'SHOW') out[idx] = 'SHOW';
          else if (action === 'HIDE' && prev !== 'SHOW') out[idx] = 'HIDE';
        }
      }
      return out;
    }

    function evaluateFieldRulesToVisibility(schema, values, rules) {
      const out = Object.create(null);
      if (!Array.isArray(rules) || !rules.length) return out;

      const cleanVals = sanitizeValues(schema, values || {});
      const getVal = (fid) => cleanVals[fid];

      const toSlug = (s) => String(s||'')
        .normalize('NFKD')
        .replace(/[\u0300-\u036f]/g, '')
        .replace(/[^a-zA-Z0-9]+/g, '_')
        .replace(/^_+|_+$/g, '')
        .toLowerCase();

      for (const r of rules) {
        if (!r) continue;

        const action = (String(r.action || '').toUpperCase() === 'SHOW') ? 'SHOW'
                    : (String(r.action || '').toUpperCase() === 'HIDE') ? 'HIDE'
                    : null;
        if (!action) continue;

        const fieldId = r.fieldId || r.field || r.whenField;
        const op      = r.op || r.operator || 'equals';
        const exp     = r.values ?? r.value ?? r.expected;
        const targets = Array.isArray(r.targets) ? r.targets : [];
        const effect  = (String(r.hideMode||'hide').toLowerCase() === 'disable') ? 'DISABLE' : 'HIDE';

        // --- match condition ---
        let match = false;

        if (typeof fieldId === 'string' && fieldId.includes('__opt__')) {
          const [baseId, slug] = fieldId.split('__opt__');
          const actualArr = Array.isArray(getVal(baseId)) ? getVal(baseId).map(String) : [];
          const selected = actualArr.some(v => toSlug(v) === String(slug||'').replace(/^_+/,'').toLowerCase());
          const expect = Array.isArray(exp) ? exp[0] : exp;
          const expectBool = (String(expect) === 'true');
          if (op === 'equals') match = (selected === expectBool);
        } else {
          const fld = (schema?.fields||[]).find(f => String(f.id) === String(fieldId));
          const t = String(fld?.type||'').toLowerCase();
          const actual = getVal(fieldId);

          if (t === 'date') {
            const expStr = Array.isArray(exp) ? String(exp[0]||'') : String(exp||'');
            const toDay = (s) => { if (!s) return NaN; const d = new Date(s); return isNaN(d) ? NaN : Date.UTC(d.getFullYear(), d.getMonth(), d.getDate()); };
            const a = toDay(actual);
            const b = toDay(expStr);
            if (Number.isNaN(a) || Number.isNaN(b)) match = false;
            else if (op === 'before') match = a < b;
            else if (op === 'after')  match = a > b;
            else if (op === 'equals') match = a === b;
          } else if (t === 'text' || t === 'number' || t === 'select') {
            const expVal = Array.isArray(exp) ? exp[0] : exp;
            if (op === 'equals')    match = String(actual) === String(expVal);
            else if (op === 'notEquals') match = String(actual) !== String(expVal);
            else if (t === 'text' && op === 'contains') match = String(actual ?? '').toLowerCase().includes(String(expVal ?? '').toLowerCase());
          } else if (t === 'multichoice') {
            match = ruleMatchesValue(op, exp, actual);
          } else {
            match = ruleMatchesValue(op, exp, actual);
          }
        }

        if (!match) continue;

        // --- apply to field/option targets ---
        for (const t of targets) {
          // field rules target either a field id or a multichoice option id ("field__opt__slug")
          const id = String(t?.id ?? t?.fieldId ?? t?.key ?? '');
          if (!id) continue;
          const prev = out[id];
          if (action === 'SHOW') out[id] = 'SHOW';
          else if (action === 'HIDE' && prev !== 'SHOW') out[id] = effect; // DISABLE or HIDE
        }
      }

      return out;
    }

    // =========================
    // FILE OPEN / SAVE / EXPORT
    // =========================
    async function doOpen() {
      const tr = TRACE('doOpen');
      try {
        clearUiForNewDoc('Openingâ€¦');

        // 1) Let the user pick a DOCX (File System Access API)
        const [handle] = await showOpenFilePicker({
          multiple: false,
          excludeAcceptAllOption: true,
          types: [{
            description: 'Word document',
            accept: { 'application/vnd.openxmlformats-officedocument.wordprocessingml.document': ['.docx', '.docm'] }
          }]
        });

        // 2) Read bytes and compute content-addressed docId via persistence.js
        const file  = await handle.getFile();
        const bytes = new Uint8Array(await file.arrayBuffer());
        const { base, ext } = splitNameAndExt(file.name || 'document.docx');
        gFileHandle = handle;
        gFileName   = base || 'document';
        gFileExt    = ext  || '.docx';

        // IMPORTANT: this call computes docId = "<basename>#<sha256:12>" from BYTES
        const metaObj = await window.formSuitePersist.setCurrentDoc({
          bytes,
          handle,
          name: `${gFileName}${gFileExt}`
        });

        // 3) Switch local context to the NEW docId (even if filename is identical)
        gDocId        = metaObj.docId;
        gArrayBuffer  = bytes.buffer;
        persistActiveMeta(metaObj);     // keep existing cross-tab signals
        announceDocSwitch();

        // 4) Re-render and refresh permission banner
        await renderFromCurrentBytes();
        await updateWriteAccessBanner({ tryPrompt: true });

        // 5) Enable actions
        btnSave.disabled = false;
        btnExport.disabled = false;
        if (btnSaveFromPreview) btnSaveFromPreview.disabled = false;

        tr.step('opened', { name: `${gFileName}${gFileExt}`, size: bytes.byteLength, docId: gDocId });
      } catch (e) {
        if (e?.name === 'AbortError') { tr.step('user canceled'); return; }
        tr.error('open failed', e);
        setStatus(`Error opening file: ${e.message || e}`);
      } finally { tr.end(); }
    }


    async function ensureWritePermission(handle) {
      const tr = TRACE('ensureWritePermission', { haveHandle: !!handle });
      try {
        if (!handle?.requestPermission) return 'denied';
        let p = await handle.queryPermission?.({ mode: 'readwrite' });
        tr.step('queryPermission', p);
        if (p === 'granted') return 'granted';
        const r = await handle.requestPermission?.({ mode: 'readwrite' });
        tr.end({ requestPermission: r });
        return r || 'denied';
      } catch (e) { tr.error('perm failed', e); tr.end(); return 'denied'; }
    }

    async function doSave() {
      const tr = TRACE('doSave');
      try {
        if (!gArrayBuffer) return;

        const restored = gDocId ? (await window.formSuitePersist.loadState(gDocId)) : null;
        if (restored) {
          adoptHeadingBaseline({
            flat: Array.isArray(restored.headingsFlat) ? restored.headingsFlat : Array.isArray(restored.headings) ? restored.headings : [],
            tree: Array.isArray(restored.headingsTree) ? restored.headingsTree : gHeadingBaseline.tree
          });
        }
        if (restored?.schema) gSchema = restored.schema;

        const domVals  = collectFormValues(gSchema);
        const baseVals = (restored && restored.values) ? restored.values : {};
        const tagMapRaw = restored?.tagMap || await getTagMapFor(gDocId);

        const payloadSnapshot = restored?.payload?.CRONOS_PAYLOAD
                              || restored?.CRONOS_PAYLOAD
                              || restored?.cronos_payload
                              || {};

        const { rules: mergedRulesRaw, fieldRules: mergedFieldRaw, source: ruleSourceMeta } =
          resolveRulesForState(restored || {}, payloadSnapshot);

        const rules      = normalizeHeadingsRulesForSchema(gSchema, mergedRulesRaw, gHeadingBaseline);
        const fieldRules = normalizeFieldRulesForSchema(gSchema, mergedFieldRaw);

        console.log('[doSave][rulesSource]', {
          source: ruleSourceMeta,
          wsRules: normalizeRuleCollection(restored?.rules).length,
          plRules: normalizeRuleCollection(payloadSnapshot?.rules).length
        });

        console.log('[doSave][normalized]', {
          rules: rules.length,
          fieldRules: fieldRules.length,
          source: ruleSourceMeta,
          wsRules: normalizeRuleCollection(restored?.rules).length,
          plRules: normalizeRuleCollection(payloadSnapshot?.rules).length
        });

        const { values: prunedValues, tagMap: prunedTagMap } =
          normalizeForSchema(gSchema, { ...baseVals, ...domVals }, tagMapRaw);

        gValues = prunedValues;
        await updatePreview(gValues);

        const payloadObj = {
          title:  gSchema.title || 'Form',
          fields: gSchema.fields || [],
          values: gValues || {},
          tagMap: prunedTagMap,
          rules,
          fieldRules,
          updatedAt: new Date().toISOString()
        };

        setStatus('Writing payload to DOCXâ€¦');
        const updated = await writeDocVarSettings(gArrayBuffer, PAYLOAD_KEY, JSON.stringify(payloadObj));
        const updatedU8 = (updated instanceof Uint8Array) ? updated : new Uint8Array(updated);
        gArrayBuffer = updatedU8.slice().buffer;

        if (gDocId) {
          const stamp = Date.now();
          await window.formSuitePersist.saveState(gDocId, {
            schema: gSchema,
            values: gValues,
            rules,
            fieldRules,
            tagMap: prunedTagMap,
            payload: { CRONOS_PAYLOAD: payloadObj },
            CRONOS_PAYLOAD: payloadObj,
            cronos_payload: payloadObj,
            rulesVersion: stamp,
            schemaUpdatedAt: new Date().toISOString()
          });
          await window.formSuitePersist.putBytes(gDocId, updatedU8);
        }

        const metaObj = await persistCurrentDoc(updatedU8, gFileHandle, gFileName, gFileExt);
        gDocId = metaObj.docId;
        persistActiveMeta(metaObj);
        announceDocUpdate();

        if (window.showSaveFilePicker && gFileHandle) {
          const p = await ensureWritePermission(gFileHandle, 'readwrite');
          if (p === 'granted') {
            const stream = await gFileHandle.createWritable();
            await stream.write(updatedU8);
            await stream.close();
            setStatus('Saved.');
            gDirty = false;
            return;
          }
        }
        setStatus('Saved in workspace (file write not available).');
        gDirty = false;
      } catch (e) {
        tr.error('failed', e);
        setStatus('Save failed.');
      } finally {
        tr.end();
      }
    }

    async function doExport() {
      const tr = TRACE('doExport');
      try {
        if (!gArrayBuffer) return;

        const originalBytes = (gArrayBuffer instanceof Uint8Array)
          ? gArrayBuffer.slice()
          : new Uint8Array(gArrayBuffer);

        const restored = gDocId ? (await window.formSuitePersist.loadState(gDocId)) : null;
        if (restored) {
          adoptHeadingBaseline({
            flat: Array.isArray(restored.headingsFlat) ? restored.headingsFlat : Array.isArray(restored.headings) ? restored.headings : [],
            tree: Array.isArray(restored.headingsTree) ? restored.headingsTree : gHeadingBaseline.tree
          });
        }
        if (restored?.schema) gSchema = restored.schema;

        const domVals  = collectFormValues(gSchema);
        const baseVals = (restored && restored.values) ? restored.values : {};
        const tagMapRaw = restored?.tagMap || await getTagMapFor(gDocId);

        const payloadSnapshot = restored?.payload?.CRONOS_PAYLOAD
                              || restored?.CRONOS_PAYLOAD
                              || restored?.cronos_payload
                              || {};

        const { rules: mergedRulesRaw, fieldRules: mergedFieldRaw, source: ruleSourceMeta } =
          resolveRulesForState(restored || {}, payloadSnapshot);

        const rules      = normalizeHeadingsRulesForSchema(gSchema, mergedRulesRaw, gHeadingBaseline);
        const fieldRules = normalizeFieldRulesForSchema(gSchema, mergedFieldRaw);

        console.log('[doExport][rulesSource]', {
          source: ruleSourceMeta,
          wsRules: normalizeRuleCollection(restored?.rules).length,
          plRules: normalizeRuleCollection(payloadSnapshot?.rules).length
        });

        const { values: prunedValues, tagMap: prunedTagMap } =
          normalizeForSchema(gSchema, { ...baseVals, ...domVals }, tagMapRaw);

        gValues = prunedValues;

        // 1) embed payload
        const payloadObj = {
          title:  gSchema.title || 'Form',
          fields: gSchema.fields || [],
          values: gValues || {},
          tagMap: prunedTagMap,
          rules,
          fieldRules,
          updatedAt: new Date().toISOString()
        };
        let updated = await writeDocVarSettings(gArrayBuffer, PAYLOAD_KEY, JSON.stringify(payloadObj));

        // 2) replace SDTs via tagMap
        const sdtMap = {};
        for (const [tag, fieldId] of Object.entries(prunedTagMap)) {
          let v = gValues?.[fieldId];
          if (v == null) v = '';
          if (typeof v === 'object')
            v = v.formatted ?? (() => { try { return JSON.stringify(v); } catch { return String(v); } })();
          sdtMap[tag] = String(v);
        }
        updated = await writeSDTs(updated, sdtMap);

        // 3) apply visibility/removal actions
        const headingResolver = buildHeadingTargetIndex(gHeadingBaseline);
        const visibilityMap = evaluateRulesToVisibility(gSchema, gValues, rules, headingResolver);
        try {
          await inspectRemovalPlan(updated, visibilityMap);
        } catch (e) { tr.warn('inspectRemovalPlan failed', e); }
        updated = await applyRemovalWithBackup(updated, visibilityMap, originalBytes);
        const updatedU8 = (updated instanceof Uint8Array) ? updated : new Uint8Array(updated);

        // 4) download/save as a new file
        const suggested = (gFileName?.replace(/\.(docx|docm|dotx|dotm)$/i,'') || 'document') + '_export.' + gFileExt;
        if (window.showSaveFilePicker) {
          try {
            const handle = await window.showSaveFilePicker({
              suggestedName: suggested,
              types: [{ description: 'Word document', accept: { [wordMimeFor(gFileExt)]: [`.${gFileExt}`] } }]
            });
            const stream = await handle.createWritable();
            await stream.write(updatedU8);
            await stream.close();
            setStatus(`Exported as â€œ${handle.name || suggested}â€.`);
            gDirty = false;
            return;
          } catch (e) {
            if (e?.name === 'AbortError') { setStatus('Export canceled.'); return; }
          }
        }
        const blob = new Blob([updatedU8], { type: wordMimeFor(gFileExt) });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a'); a.href = url; a.download = suggested; a.click();
        URL.revokeObjectURL(url);
        setStatus(`Exported as â€œ${suggested}â€.`);
        gDirty = false;
      } catch (e) {
        tr.error('failed', e);
        setStatus('Export failed.');
      } finally {
        tr.end();
      }
    }

    // =========================
    // PAYLOAD PREVIEW (editable)
    // =========================
    let __payloadApplyTimer = null;
    let __payloadEditBusy = false;

    async function applyPayloadObject(obj, { broadcast = true, save = true } = {}) {
      const tr = TRACE('applyPayloadObject');
      try {
        if (!obj || typeof obj !== 'object') return;

        const nextSchema = { title: obj.title || 'Form', fields: Array.isArray(obj.fields) ? obj.fields : [] };
        const rawValues  = (obj.values && typeof obj.values === 'object') ? obj.values : {};
        const rawTagMap  = (obj.tagMap && typeof obj.tagMap === 'object') ? obj.tagMap : {};

        const rawRules   = Array.isArray(obj.rules) ? obj.rules : [];
        const rawFieldR  = Array.isArray(obj.fieldRules) ? obj.fieldRules : [];

        const rules      = normalizeHeadingsRulesForSchema(nextSchema, rawRules, gHeadingBaseline);
        const fieldRules = normalizeFieldRulesForSchema(nextSchema, rawFieldR);

        console.log('[applyPayloadObject][normalized]', {
          rules: rules.length,
          fieldRules: fieldRules.length,
          sampleFR: fieldRules[0]
        });

        const { values: prunedValues, tagMap: prunedTagMap } =
          normalizeForSchema(nextSchema, rawValues, rawTagMap);

        gSchema = nextSchema;
        gValues = prunedValues;

        const payloadObj = {
          title: gSchema.title,
          fields: gSchema.fields,
          values: gValues,
          tagMap: prunedTagMap,
          rules,
          fieldRules,
          updatedAt: new Date().toISOString()
        };

        if (gDocId && save) {
          await window.formSuitePersist.saveState(gDocId, {
            schema: gSchema,
            values: gValues,
            tagMap: prunedTagMap,
            rules, fieldRules,
            payload: { CRONOS_PAYLOAD: payloadObj },
            CRONOS_PAYLOAD: payloadObj,
            cronos_payload: payloadObj,
            schemaUpdatedAt: new Date().toISOString()
          });
        } else {
          try { localStorage.setItem(STORAGE_KEY, JSON.stringify({ title: gSchema.title, fields: gSchema.fields })); } catch {}
        }

        buildForm(document.getElementById('formMount'), gSchema, gValues);
        await updatePreview(gValues);

        if (broadcast) {
          try { bcLegacy?.postMessage({ type: 'schema-updated', docId: gDocId, ts: Date.now() }); } catch {}
          try { bcCanon?.postMessage({ type: 'schema-updated',  docId: gDocId, ts: Date.now() }); } catch {}
        }

        gDirty = true;
        setStatus('Payload applied (normalized). Not yet saved to DOCX.');
        if (previewStatus) { previewStatus.textContent = 'Applied'; setTimeout(()=> previewStatus.textContent='', 900); }
      } finally {
        tr.end();
      }
    }


    if (payloadEl) {
      payloadEl.addEventListener('input', () => {
        const tr = TRACE('payloadEl:input');
        try {
          clearTimeout(__payloadApplyTimer);
          __payloadApplyTimer = setTimeout(async () => {
            const tr2 = TRACE('payloadEl:debouncedApply');
            if (__payloadEditBusy) { tr2.step('busy skip'); tr2.end(); return; }
            try {
              const txt = payloadEl.value;
              const obj = JSON.parse(txt);
              __payloadEditBusy = true;
              await applyPayloadObject(obj);
            } catch (e) {
              if (previewStatus) previewStatus.textContent = 'Invalid JSON';
              tr2.warn('invalid JSON', e);
            } finally {
              __payloadEditBusy = false;
              tr2.end();
            }
          }, 350);
        } finally { tr.end(); }
      });
    }

    // =========================
    // WIRE UP UI
    // =========================
    btnOpen.addEventListener('click', doOpen);
    btnSave.addEventListener('click', doSave);
    btnExport.addEventListener('click', doExport);
    btnSaveFromPreview?.addEventListener('click', doSave);

    btnRegrant.addEventListener('click', async () => {
      const tr = TRACE('btnRegrant:click');
      try { await updateWriteAccessBanner({ tryPrompt: true }); }
      catch (e) { tr.error('regrant failed', e); permNote.style.display='block'; }
      finally { tr.end(); }
    });

    window.addEventListener('beforeunload', async () => {
      const tr = TRACE('beforeunload');
      try {
        if (!gDocId) { tr.end('no docId'); return; }
        const vals = collectFormValues(gSchema);
        await window.formSuitePersist.saveState(gDocId, { schema: gSchema, values: { ...(gValues||{}), ...vals } });
        persistActiveMeta({ docId: gDocId, name: gFileName });
      } catch (e) { tr.warn('beforeunload failed', e); }
      finally { tr.end(); }
    });

    // =========================
    // TRIPLE-CLICK FOCUS NAV
    // =========================
    (function() {
      const logo = document.querySelector('header .logo');
      const header = document.querySelector('header .row');
      if (!logo || !header) return;

      let clickCount = 0;
      let clickTimer = null;
      let focusMode = false;

      logo.addEventListener('click', () => {
        clickCount++;
        clearTimeout(clickTimer);
        clickTimer = setTimeout(() => { clickCount = 0; }, 600);

        if (clickCount === 3) {
          clickCount = 0;
          focusMode = !focusMode;

          if (focusMode) {
            header.querySelectorAll('a, span.muted').forEach(el => {
              if (!el.closest('.brand')) el.style.display = 'none';
            });
            if (!location.pathname.endsWith('index.html')) location.href = 'index.html';
          } else {
            header.querySelectorAll('a, span.muted').forEach(el => { el.style.display = ''; });
          }
        }
      });
    })();

    // =========================
    // HEADINGS (H1..H9) PARSING & TREE
    // =========================

    async function parseHeadings_JS(arrayBuffer) {
      const tr = TRACE('parseHeadings_JS', { hasBuffer: !!arrayBuffer, len: arrayBuffer?.byteLength });
      try {
        if (!arrayBuffer) return { flat: [], tree: [], count: 0 };

        const bytes = (arrayBuffer instanceof Uint8Array) ? arrayBuffer : new Uint8Array(arrayBuffer);
        const plan = await inspectRemovalPlan(bytes, {});
        const parts = Array.isArray(plan?.parts) ? plan.parts : [];

        const seen = new Set();
        const flat = [];

        for (const part of parts) {
          const headings = Array.isArray(part?.headings) ? part.headings : [];
          for (const heading of headings) {
            const idx = Number(heading?.idx);
            if (!Number.isFinite(idx) || seen.has(idx)) continue;
            seen.add(idx);
            const text = String(heading?.text || '').trim();
            const lvl = Number(heading?.level);
            const entry = {
              idx,
              key: idx,
              id: idx,
              text,
              title: text,
              label: text,
              part: heading?.part || part?.name || 'document'
            };
            if (Number.isFinite(lvl)) entry.level = lvl;
            const number = heading?.number ?? heading?.num;
            if (number != null && number !== '') entry.number = String(number);
            flat.push(entry);
          }
        }

        if (!flat.length) { tr.end({ count: 0, reason: 'no-headings' }); return { flat: [], tree: [], count: 0 }; }

        flat.sort((a, b) => a.idx - b.idx);

        const tree = buildHeadingTree(flat);
        numberHeadingsTree(tree);

        const byIdx = new Map(flat.map(h => [Number(h.idx), h]));
        const propagate = (nodes) => {
          if (!Array.isArray(nodes)) return;
          for (const n of nodes) {
            if (byIdx.has(Number(n.idx))) {
              const ref = byIdx.get(Number(n.idx));
              if (n.num) {
                ref.number = n.num;
                ref.compositeKey = `${n.num}|${ref.text}`.trim();
              }
            }
            if (Array.isArray(n.children) && n.children.length) propagate(n.children);
          }
        };
        propagate(tree);

        flat.forEach((h) => {
          const num = h.number || h.num;
          const idx = Number(h.idx);
          const prefix = num ? String(num) : Number.isFinite(idx) ? String(idx + 1) : '';
          if (!h.compositeKey) h.compositeKey = `${prefix}|${h.text}`.trim();
        });

        tr.end({ count: flat.length, rootChildren: tree.length });
        return { flat, tree, count: flat.length };
      } catch (e) {
        tr.error('failed', e); tr.end();
        return { flat: [], tree: [], count: 0 };
      }
    }

    function buildHeadingTree(list) {
      const root = [];
      const stack = [];
      for (const h of (list || [])) {
        const node = {
          level: h.level,
          text: h.text,
          part: h.part || 'document',
          idx: h.idx,
          uid: h.uid,
          paraIndex: h.paraIndex,
          start: h.start,
          end: h.end,
          label: h.label || h.text,
          children: []
        };
        while (stack.length && stack[stack.length - 1].level >= node.level) stack.pop();
        if (!stack.length) {
          root.push(node);
        } else {
          stack[stack.length - 1].children.push(node);
        }
        stack.push(node);
      }
      return root;
    }

    function renderHeadingsTreeView(tree) {
      const tr = TRACE('renderHeadingsTreeView', { nodes: tree?.length || 0 });
      try {
        if (!headersTreeEl) return;
        headersTreeEl.innerHTML = '';
        if (!tree || !tree.length) {
          headersTreeEl.innerHTML = '<div class="empty">No headings found (no paragraphs styled as headings).</div>';
          tr.end('empty'); return;
        }

        numberHeadingsTree(tree);

        const mk = (nodes) => {
          const ul = document.createElement('ul');
          ul.style.margin = '0 0 0 1rem';
          ul.style.padding = '0.1rem 0 0.1rem 0.6rem';
          for (const n of nodes) {
            const li = document.createElement('li');
            li.style.listStyle = 'none';

            const line = document.createElement('div');
            line.style.display = 'flex';
            line.style.gap = '6px';
            line.style.alignItems = 'baseline';

            const num = document.createElement('span');
            num.textContent = n.num;
            num.style.minWidth = '4ch';
            num.style.textAlign = 'right';
            num.style.fontVariantNumeric = 'tabular-nums';
            num.style.opacity = '0.9';
            num.style.fontWeight = n.level <= 2 ? '700' : '600';

            const text = document.createElement('span');
            text.textContent = n.text;
            text.title = `${n.part} â€¢ H${n.level}`;
            text.style.fontWeight = n.level <= 2 ? '600' : '400';

            const part = document.createElement('span');
            part.textContent = `Â· ${n.part}`;
            part.className = 'muted';
            part.style.fontSize = '0.75rem';

            line.appendChild(num);
            line.appendChild(text);
            line.appendChild(part);
            li.appendChild(line);

            if (n.children?.length) li.appendChild(mk(n.children));
            ul.appendChild(li);
          }
          return ul;
        };

        headersTreeEl.appendChild(mk(tree));
        tr.end('rendered');
      } catch (e) { tr.error('failed', e); tr.end(); }
    }

  </script>
</body>
</html>
